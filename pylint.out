************* Module bpf_be_fastapi.experimenting
experimenting.py:48:17: E0001: Parsing failed: 'expected '(' (bpf_be_fastapi.experimenting, line 48)' (syntax-error)
************* Module bpf_be_fastapi.classes1
classes1.py:10:22: E0001: Parsing failed: 'invalid syntax (bpf_be_fastapi.classes1, line 10)' (syntax-error)
************* Module bpf_be_fastapi.classes
classes.py:364:13: E0001: Parsing failed: 'invalid syntax (bpf_be_fastapi.classes, line 364)' (syntax-error)
************* Module bpf_be_fastapi
__init__.py:2:0: C0305: Trailing newlines (trailing-newlines)
************* Module bpf_be_fastapi.test_parse_date_1
test_parse_date_1.py:2:0: E0401: Unable to import 'parse_date_1' (import-error)
************* Module bpf_be_fastapi.display_records
display_records.py:5:0: E0401: Unable to import 'db_actions' (import-error)
display_records.py:6:0: E0401: Unable to import 'classes' (import-error)
************* Module bpf_be_fastapi._test_parsing_manifests
_test_parsing_manifests.py:1:0: C0114: Missing module docstring (missing-module-docstring)
_test_parsing_manifests.py:3:0: E0401: Unable to import 'parse_manifests' (import-error)
_test_parsing_manifests.py:4:0: E0401: Unable to import 'db_actions' (import-error)
_test_parsing_manifests.py:8:0: C0116: Missing function or method docstring (missing-function-docstring)
_test_parsing_manifests.py:9:8: W1514: Using open without explicitly specifying an encoding (unspecified-encoding)
_test_parsing_manifests.py:9:8: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
_test_parsing_manifests.py:21:0: C0116: Missing function or method docstring (missing-function-docstring)
_test_parsing_manifests.py:22:8: W1514: Using open without explicitly specifying an encoding (unspecified-encoding)
_test_parsing_manifests.py:22:8: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
_test_parsing_manifests.py:36:0: C0116: Missing function or method docstring (missing-function-docstring)
_test_parsing_manifests.py:37:8: W1514: Using open without explicitly specifying an encoding (unspecified-encoding)
_test_parsing_manifests.py:37:8: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
_test_parsing_manifests.py:49:0: C0116: Missing function or method docstring (missing-function-docstring)
_test_parsing_manifests.py:50:8: W1514: Using open without explicitly specifying an encoding (unspecified-encoding)
_test_parsing_manifests.py:50:8: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
_test_parsing_manifests.py:64:0: C0116: Missing function or method docstring (missing-function-docstring)
_test_parsing_manifests.py:65:8: W1514: Using open without explicitly specifying an encoding (unspecified-encoding)
_test_parsing_manifests.py:65:8: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
_test_parsing_manifests.py:5:0: C0411: third party import "pytest" should be placed before first party imports "parse_manifests", "db_actions"  (wrong-import-order)
_test_parsing_manifests.py:6:0: C0411: third party import "pytest_asyncio" should be placed before first party imports "parse_manifests", "db_actions"  (wrong-import-order)
_test_parsing_manifests.py:5:0: W0611: Unused import pytest (unused-import)
_test_parsing_manifests.py:6:0: W0611: Unused import pytest_asyncio (unused-import)
************* Module bpf_be_fastapi.test_parse_gnd
test_parse_gnd.py:39:0: C0301: Line too long (116/100) (line-too-long)
test_parse_gnd.py:7:0: E0401: Unable to import 'db_actions' (import-error)
test_parse_gnd.py:8:0: E0401: Unable to import 'parse_gnd' (import-error)
test_parse_gnd.py:63:4: W0622: Redefining built-in 'max' (redefined-builtin)
test_parse_gnd.py:51:4: W0105: String statement has no effect (pointless-string-statement)
test_parse_gnd.py:58:4: W0105: String statement has no effect (pointless-string-statement)
test_parse_gnd.py:67:4: W0105: String statement has no effect (pointless-string-statement)
************* Module bpf_be_fastapi.ingest_place
ingest_place.py:519:0: C0305: Trailing newlines (trailing-newlines)
ingest_place.py:9:0: E0401: Unable to import 'classes' (import-error)
ingest_place.py:10:0: E0401: Unable to import 'db_actions' (import-error)
ingest_place.py:11:0: E0401: Unable to import 'get_external_data' (import-error)
ingest_place.py:12:0: E0401: Unable to import 'person_relations' (import-error)
ingest_place.py:13:0: E0401: Unable to import 'parsing_helpers' (import-error)
ingest_place.py:16:0: C0116: Missing function or method docstring (missing-function-docstring)
ingest_place.py:66:0: C0116: Missing function or method docstring (missing-function-docstring)
ingest_place.py:128:0: R0914: Too many local variables (36/15) (too-many-locals)
ingest_place.py:167:8: R1723: Unnecessary "elif" after "break", remove the leading "el" from "elif" (no-else-break)
ingest_place.py:172:12: R1723: Unnecessary "else" after "break", remove the "else" and de-indent the code inside it (no-else-break)
ingest_place.py:464:20: R1723: Unnecessary "else" after "break", remove the "else" and de-indent the code inside it (no-else-break)
ingest_place.py:128:0: R0912: Too many branches (54/12) (too-many-branches)
ingest_place.py:128:0: R0915: Too many statements (219/50) (too-many-statements)
ingest_place.py:136:4: W0612: Unused variable 'org_found' (unused-variable)
************* Module bpf_be_fastapi.parse_istc_old
parse_istc_old.py:159:0: W0311: Bad indentation. Found 36 spaces, expected 32 (bad-indentation)
parse_istc_old.py:509:0: C0304: Final newline missing (missing-final-newline)
parse_istc_old.py:5:0: E0401: Unable to import 'classes' (import-error)
parse_istc_old.py:6:0: E0401: Unable to import 'get_external_data' (import-error)
parse_istc_old.py:12:0: R0914: Too many local variables (30/15) (too-many-locals)
parse_istc_old.py:76:4: R1702: Too many nested blocks (9/5) (too-many-nested-blocks)
parse_istc_old.py:76:4: R1702: Too many nested blocks (9/5) (too-many-nested-blocks)
parse_istc_old.py:12:0: R0912: Too many branches (33/12) (too-many-branches)
parse_istc_old.py:12:0: R0915: Too many statements (118/50) (too-many-statements)
parse_istc_old.py:247:0: C0116: Missing function or method docstring (missing-function-docstring)
parse_istc_old.py:247:0: R0914: Too many local variables (29/15) (too-many-locals)
parse_istc_old.py:419:15: R1714: Consider merging these comparisons with 'in' by using 'date_prefix in ('About ', 'about ')'. Use a set instead if elements are hashable. (consider-using-in)
parse_istc_old.py:247:0: R0912: Too many branches (44/12) (too-many-branches)
parse_istc_old.py:247:0: R0915: Too many statements (159/50) (too-many-statements)
parse_istc_old.py:265:4: W0612: Unused variable 'date_between_indicator' (unused-variable)
parse_istc_old.py:269:4: W0612: Unused variable 'string_prefix' (unused-variable)
parse_istc_old.py:270:4: W0612: Unused variable 'string_day' (unused-variable)
parse_istc_old.py:271:4: W0612: Unused variable 'string_month' (unused-variable)
parse_istc_old.py:272:4: W0612: Unused variable 'string_year' (unused-variable)
parse_istc_old.py:274:4: W0612: Unused variable 'string_month_between' (unused-variable)
parse_istc_old.py:275:4: W0612: Unused variable 'string_year_between' (unused-variable)
parse_istc_old.py:276:4: W0612: Unused variable 'start_month' (unused-variable)
parse_istc_old.py:277:4: W0612: Unused variable 'start_day' (unused-variable)
parse_istc_old.py:278:4: W0612: Unused variable 'start_year' (unused-variable)
************* Module bpf_be_fastapi.books_parsing_bibliographies
books_parsing_bibliographies.py:16:0: E0401: Unable to import 'classes' (import-error)
books_parsing_bibliographies.py:17:0: E0401: Unable to import 'parsing_helpers' (import-error)
books_parsing_bibliographies.py:22:0: R0914: Too many local variables (35/15) (too-many-locals)
books_parsing_bibliographies.py:22:0: R0912: Too many branches (18/12) (too-many-branches)
books_parsing_bibliographies.py:22:0: R0915: Too many statements (85/50) (too-many-statements)
books_parsing_bibliographies.py:22:0: R1710: Either all return statements in a function should return an expression, or none of them should. (inconsistent-return-statements)
books_parsing_bibliographies.py:30:10: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
books_parsing_bibliographies.py:75:4: W0612: Unused variable 'person_list_pattern' (unused-variable)
books_parsing_bibliographies.py:76:4: W0612: Unused variable 'person_single_pattern' (unused-variable)
books_parsing_bibliographies.py:132:12: W0612: Unused variable 'impressum_single_person1' (unused-variable)
books_parsing_bibliographies.py:142:12: W0612: Unused variable 'impressum_single_person2' (unused-variable)
books_parsing_bibliographies.py:11:0: W0611: Unused import xml.etree.ElementTree (unused-import)
books_parsing_bibliographies.py:17:0: W0611: Unused import parsing_helpers (unused-import)
************* Module bpf_be_fastapi.test_parse_istc
test_parse_istc.py:10:0: E0401: Unable to import 'parse_istc' (import-error)
test_parse_istc.py:5:0: W0611: Unused print imported from rich (unused-import)
test_parse_istc.py:10:0: W0611: Unused import parse_istc (unused-import)
************* Module bpf_be_fastapi.parsing_helpers
parsing_helpers.py:8:0: E0401: Unable to import 'classes' (import-error)
parsing_helpers.py:9:0: E0401: Unable to import 'person_relations' (import-error)
parsing_helpers.py:144:0: R0912: Too many branches (17/12) (too-many-branches)
parsing_helpers.py:228:0: R0912: Too many branches (25/12) (too-many-branches)
parsing_helpers.py:228:0: R0915: Too many statements (55/50) (too-many-statements)
************* Module bpf_be_fastapi.ingest_organisation
ingest_organisation.py:7:0: E0401: Unable to import 'classes' (import-error)
ingest_organisation.py:8:0: E0401: Unable to import 'db_actions' (import-error)
ingest_organisation.py:9:0: E0401: Unable to import 'get_external_data' (import-error)
ingest_organisation.py:10:0: E0401: Unable to import 'person_relations' (import-error)
ingest_organisation.py:11:0: E0401: Unable to import 'parsing_helpers' (import-error)
ingest_organisation.py:16:0: R0914: Too many local variables (36/15) (too-many-locals)
ingest_organisation.py:37:8: R1723: Unnecessary "elif" after "break", remove the leading "el" from "elif" (no-else-break)
ingest_organisation.py:42:12: R1723: Unnecessary "else" after "break", remove the "else" and de-indent the code inside it (no-else-break)
ingest_organisation.py:220:4: R1702: Too many nested blocks (6/5) (too-many-nested-blocks)
ingest_organisation.py:327:20: R1723: Unnecessary "else" after "break", remove the "else" and de-indent the code inside it (no-else-break)
ingest_organisation.py:16:0: R0912: Too many branches (71/12) (too-many-branches)
ingest_organisation.py:16:0: R0915: Too many statements (240/50) (too-many-statements)
************* Module bpf_be_fastapi.test_parse_iiif
test_parse_iiif.py:8:0: W0622: Redefining built-in 'print' (redefined-builtin)
test_parse_iiif.py:22:0: E0401: Unable to import 'db_actions' (import-error)
test_parse_iiif.py:23:0: E0401: Unable to import 'parse_iiif' (import-error)
************* Module bpf_be_fastapi.test_ingest_person
test_ingest_person.py:5:0: C0301: Line too long (3333/100) (line-too-long)
************* Module bpf_be_fastapi.parse_manifests
parse_manifests.py:1:0: C0302: Too many lines in module (2667/1000) (too-many-lines)
parse_manifests.py:15:0: W0622: Redefining built-in 'print' (redefined-builtin)
parse_manifests.py:17:0: E0401: Unable to import 'classes' (import-error)
parse_manifests.py:18:0: E0401: Unable to import 'parse_canvas' (import-error)
parse_manifests.py:19:0: E0401: Unable to import 'parsing_helpers' (import-error)
parse_manifests.py:59:8: W0622: Redefining built-in 'id' (redefined-builtin)
parse_manifests.py:69:14: I1101: Module 'lxml.etree' has no 'fromstring' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_manifests.py:99:7: R0133: Comparison between constants: '1 == 2' has a constant value (comparison-of-constants)
parse_manifests.py:102:25: E0602: Undefined variable 'manifest' (undefined-variable)
parse_manifests.py:106:8: E0602: Undefined variable 'm' (undefined-variable)
parse_manifests.py:119:8: E0602: Undefined variable 'm' (undefined-variable)
parse_manifests.py:10:0: W0611: Unused import json (unused-import)
parse_manifests.py:12:0: W0611: Unused import xml.etree.ElementTree (unused-import)
parse_manifests.py:13:0: W0611: Unused import requests (unused-import)
parse_manifests.py:15:0: W0611: Unused print imported from rich (unused-import)
************* Module bpf_be_fastapi.parse_canvas
parse_canvas.py:8:0: C0301: Line too long (124/100) (line-too-long)
parse_canvas.py:9:0: C0301: Line too long (118/100) (line-too-long)
parse_canvas.py:28:0: C0301: Line too long (124/100) (line-too-long)
parse_canvas.py:29:0: C0301: Line too long (118/100) (line-too-long)
parse_canvas.py:31:0: C0301: Line too long (114/100) (line-too-long)
parse_canvas.py:46:0: C0304: Final newline missing (missing-final-newline)
parse_canvas.py:1:0: C0114: Missing module docstring (missing-module-docstring)
parse_canvas.py:3:0: E0401: Unable to import 'classes' (import-error)
************* Module bpf_be_fastapi.test_get_external_data
test_get_external_data.py:54:0: C0301: Line too long (113/100) (line-too-long)
test_get_external_data.py:58:0: C0304: Final newline missing (missing-final-newline)
test_get_external_data.py:1:0: C0114: Missing module docstring (missing-module-docstring)
test_get_external_data.py:12:0: E0401: Unable to import 'get_external_data' (import-error)
test_get_external_data.py:15:0: E0401: Unable to import 'classes' (import-error)
test_get_external_data.py:16:0: E0401: Unable to import 'db_actions' (import-error)
test_get_external_data.py:23:0: C0116: Missing function or method docstring (missing-function-docstring)
test_get_external_data.py:26:4: R1705: Unnecessary "else" after "return", remove the "else" and de-indent the code inside it (no-else-return)
test_get_external_data.py:28:12: W1514: Using open without explicitly specifying an encoding (unspecified-encoding)
test_get_external_data.py:22:0: W0613: Unused argument 'kwargs' (unused-argument)
test_get_external_data.py:45:0: C0116: Missing function or method docstring (missing-function-docstring)
test_get_external_data.py:28:12: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
test_get_external_data.py:37:21: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
test_get_external_data.py:51:0: C0116: Missing function or method docstring (missing-function-docstring)
test_get_external_data.py:14:0: C0411: standard import "logging" should be placed before third party imports "pytest", "pytest_asyncio", "dotenv.load_dotenv" and first party import "get_external_data"  (wrong-import-order)
test_get_external_data.py:7:0: W0611: Unused import pytest_asyncio (unused-import)
test_get_external_data.py:14:0: W0611: Unused import logging (unused-import)
test_get_external_data.py:15:0: W0611: Unused import classes (unused-import)
************* Module bpf_be_fastapi.person_relations
person_relations.py:1849:0: C0325: Unnecessary parens after 'return' keyword (superfluous-parens)
person_relations.py:1:0: C0302: Too many lines in module (1897/1000) (too-many-lines)
person_relations.py:1897:0: C0305: Trailing newlines (trailing-newlines)
person_relations.py:9:0: C0116: Missing function or method docstring (missing-function-docstring)
person_relations.py:504:13: R1714: Consider merging these comparisons with 'in' by using 'relation_type in ('beza', 'rela')'. Use a set instead if elements are hashable. (consider-using-in)
person_relations.py:9:0: R0912: Too many branches (14/12) (too-many-branches)
person_relations.py:535:0: C0116: Missing function or method docstring (missing-function-docstring)
person_relations.py:542:31: W0109: Duplicate key 'mitgründer' in dictionary (duplicate-key)
person_relations.py:743:11: E0606: Possibly using variable 'relation_new' before assignment (possibly-used-before-assignment)
person_relations.py:746:0: C0116: Missing function or method docstring (missing-function-docstring)
person_relations.py:746:0: R0914: Too many local variables (16/15) (too-many-locals)
person_relations.py:875:21: R1714: Consider merging these comparisons with 'in' by using 'relation in ('auch studien- u. wohnort', 'auch studien- und wohnort')'. Use a set instead if elements are hashable. (consider-using-in)
person_relations.py:911:4: W0105: String statement has no effect (pointless-string-statement)
person_relations.py:746:0: R0912: Too many branches (27/12) (too-many-branches)
person_relations.py:746:0: R0915: Too many statements (64/50) (too-many-statements)
person_relations.py:746:49: W0613: Unused argument 'sex' (unused-argument)
person_relations.py:923:0: C0116: Missing function or method docstring (missing-function-docstring)
person_relations.py:1032:0: C0116: Missing function or method docstring (missing-function-docstring)
person_relations.py:1116:0: C0116: Missing function or method docstring (missing-function-docstring)
person_relations.py:1151:8: W0105: String statement has no effect (pointless-string-statement)
person_relations.py:1116:46: W0613: Unused argument 'sex' (unused-argument)
person_relations.py:1173:0: C0116: Missing function or method docstring (missing-function-docstring)
person_relations.py:1173:49: W0613: Unused argument 'sex' (unused-argument)
person_relations.py:1221:46: W0613: Unused argument 'sex' (unused-argument)
person_relations.py:1253:0: C0116: Missing function or method docstring (missing-function-docstring)
person_relations.py:1253:48: W0613: Unused argument 'sex' (unused-argument)
person_relations.py:1299:0: C0116: Missing function or method docstring (missing-function-docstring)
************* Module bpf_be_fastapi.parse_gnd_old
parse_gnd_old.py:11:0: E0401: Unable to import 'get_external_data' (import-error)
parse_gnd_old.py:12:0: E0401: Unable to import 'parse_date' (import-error)
parse_gnd_old.py:13:0: E0401: Unable to import 'parsing_helpers' (import-error)
parse_gnd_old.py:14:0: E0401: Unable to import 'db_actions' (import-error)
parse_gnd_old.py:15:0: E0401: Unable to import 'classes' (import-error)
parse_gnd_old.py:31:0: R0914: Too many local variables (21/15) (too-many-locals)
parse_gnd_old.py:55:11: E0602: Undefined variable 'person_found' (undefined-variable)
parse_gnd_old.py:58:33: E0602: Undefined variable 'person_found' (undefined-variable)
parse_gnd_old.py:59:46: E0602: Undefined variable 'person_found' (undefined-variable)
parse_gnd_old.py:60:41: E0602: Undefined variable 'person_found' (undefined-variable)
parse_gnd_old.py:93:32: E0601: Using variable 'candidates_result' before assignment (used-before-assignment)
parse_gnd_old.py:106:28: E0602: Undefined variable 'coll' (undefined-variable)
parse_gnd_old.py:31:0: R0912: Too many branches (23/12) (too-many-branches)
parse_gnd_old.py:31:0: R0915: Too many statements (82/50) (too-many-statements)
parse_gnd_old.py:45:4: W0612: Unused variable 'gnd_id_in' (unused-variable)
parse_gnd_old.py:46:4: W0612: Unused variable 'xx' (unused-variable)
parse_gnd_old.py:211:0: R0914: Too many local variables (19/15) (too-many-locals)
parse_gnd_old.py:211:0: R0912: Too many branches (21/12) (too-many-branches)
parse_gnd_old.py:211:0: R0915: Too many statements (72/50) (too-many-statements)
parse_gnd_old.py:360:0: R0914: Too many local variables (18/15) (too-many-locals)
parse_gnd_old.py:360:0: R0912: Too many branches (21/12) (too-many-branches)
parse_gnd_old.py:360:0: R0915: Too many statements (76/50) (too-many-statements)
parse_gnd_old.py:514:0: R0914: Too many local variables (28/15) (too-many-locals)
parse_gnd_old.py:514:0: R0912: Too many branches (52/12) (too-many-branches)
parse_gnd_old.py:514:0: R0915: Too many statements (147/50) (too-many-statements)
parse_gnd_old.py:520:10: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
parse_gnd_old.py:784:0: R0914: Too many local variables (30/15) (too-many-locals)
parse_gnd_old.py:784:0: R0912: Too many branches (45/12) (too-many-branches)
parse_gnd_old.py:784:0: R0915: Too many statements (142/50) (too-many-statements)
parse_gnd_old.py:790:10: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
parse_gnd_old.py:1006:0: R0914: Too many local variables (24/15) (too-many-locals)
parse_gnd_old.py:1006:0: R0912: Too many branches (46/12) (too-many-branches)
parse_gnd_old.py:1006:0: R0915: Too many statements (142/50) (too-many-statements)
parse_gnd_old.py:1248:10: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
parse_gnd_old.py:1269:18: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
parse_gnd_old.py:8:0: W0611: Unused import os (unused-import)
parse_gnd_old.py:9:0: W0611: Unused MongoClient imported from pymongo (unused-import)
************* Module bpf_be_fastapi.ingest_person
ingest_person.py:8:0: E0401: Unable to import 'classes' (import-error)
ingest_person.py:9:0: E0401: Unable to import 'db_actions' (import-error)
ingest_person.py:10:0: E0401: Unable to import 'person_relations' (import-error)
ingest_person.py:11:0: E0401: Unable to import 'parse_date' (import-error)
ingest_person.py:12:0: E0401: Unable to import 'get_external_data' (import-error)
ingest_person.py:13:0: E0401: Unable to import 'parsing_helpers' (import-error)
ingest_person.py:17:0: R0914: Too many local variables (44/15) (too-many-locals)
ingest_person.py:199:20: W0632: Possible unbalanced tuple unpacking with sequence '()': left side has 3 labels, right side has 0 values (unbalanced-tuple-unpacking)
ingest_person.py:359:4: R1702: Too many nested blocks (6/5) (too-many-nested-blocks)
ingest_person.py:504:20: R1723: Unnecessary "else" after "break", remove the "else" and de-indent the code inside it (no-else-break)
ingest_person.py:17:0: R0912: Too many branches (67/12) (too-many-branches)
ingest_person.py:17:0: R0915: Too many statements (236/50) (too-many-statements)
ingest_person.py:7:0: W0611: Unused generate imported from nanoid (unused-import)
************* Module bpf_be_fastapi.db_actions
db_actions.py:16:0: E0401: Unable to import 'classes' (import-error)
db_actions.py:164:0: R0913: Too many arguments (9/5) (too-many-arguments)
db_actions.py:164:0: R0914: Too many local variables (19/15) (too-many-locals)
************* Module bpf_be_fastapi.test_parsing_helpers
test_parsing_helpers.py:13:51: C0303: Trailing whitespace (trailing-whitespace)
test_parsing_helpers.py:5:0: E0401: Unable to import 'parsing_helpers' (import-error)
test_parsing_helpers.py:7:0: C0116: Missing function or method docstring (missing-function-docstring)
test_parsing_helpers.py:11:0: C0116: Missing function or method docstring (missing-function-docstring)
test_parsing_helpers.py:16:0: C0116: Missing function or method docstring (missing-function-docstring)
test_parsing_helpers.py:21:0: C0116: Missing function or method docstring (missing-function-docstring)
test_parsing_helpers.py:26:0: C0116: Missing function or method docstring (missing-function-docstring)
test_parsing_helpers.py:31:0: C0116: Missing function or method docstring (missing-function-docstring)
test_parsing_helpers.py:36:0: C0116: Missing function or method docstring (missing-function-docstring)
************* Module bpf_be_fastapi.doxygen_preprocessor
doxygen_preprocessor.py:77:0: C0305: Trailing newlines (trailing-newlines)
doxygen_preprocessor.py:1:0: C0114: Missing module docstring (missing-module-docstring)
doxygen_preprocessor.py:5:0: C0116: Missing function or method docstring (missing-function-docstring)
doxygen_preprocessor.py:30:16: W0622: Redefining built-in 'list' (redefined-builtin)
doxygen_preprocessor.py:54:4: W0101: Unreachable code (unreachable)
doxygen_preprocessor.py:30:16: W0612: Unused variable 'list' (unused-variable)
doxygen_preprocessor.py:57:0: C0116: Missing function or method docstring (missing-function-docstring)
doxygen_preprocessor.py:61:9: W1514: Using open without explicitly specifying an encoding (unspecified-encoding)
doxygen_preprocessor.py:70:12: W1514: Using open without explicitly specifying an encoding (unspecified-encoding)
doxygen_preprocessor.py:70:12: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
************* Module bpf_be_fastapi.parse_artist_record
parse_artist_record.py:5:0: E0401: Unable to import 'classes' (import-error)
parse_artist_record.py:6:0: E0401: Unable to import 'parse_date' (import-error)
parse_artist_record.py:11:0: R0914: Too many local variables (31/15) (too-many-locals)
parse_artist_record.py:11:0: R0912: Too many branches (102/12) (too-many-branches)
parse_artist_record.py:11:0: R0915: Too many statements (410/50) (too-many-statements)
************* Module bpf_be_fastapi.parse_gnd
parse_gnd.py:1313:0: C0325: Unnecessary parens after 'return' keyword (superfluous-parens)
parse_gnd.py:1445:0: C0325: Unnecessary parens after 'return' keyword (superfluous-parens)
parse_gnd.py:1479:0: C0325: Unnecessary parens after 'return' keyword (superfluous-parens)
parse_gnd.py:1577:0: C0325: Unnecessary parens after 'return' keyword (superfluous-parens)
parse_gnd.py:1682:0: C0325: Unnecessary parens after 'return' keyword (superfluous-parens)
parse_gnd.py:16:0: W0622: Redefining built-in 'print' (redefined-builtin)
parse_gnd.py:18:0: E0401: Unable to import 'classes' (import-error)
parse_gnd.py:19:0: E0401: Unable to import 'db_actions' (import-error)
parse_gnd.py:20:0: E0401: Unable to import 'get_external_data' (import-error)
parse_gnd.py:21:0: E0401: Unable to import 'parse_date' (import-error)
parse_gnd.py:22:0: E0401: Unable to import 'parsing_helpers' (import-error)
parse_gnd.py:37:0: R0914: Too many local variables (16/15) (too-many-locals)
parse_gnd.py:92:4: W0612: Unused variable 'internal_id_person_type1_needed' (unused-variable)
parse_gnd.py:150:8: W0612: Unused variable 'person_found' (unused-variable)
parse_gnd.py:285:0: R0914: Too many local variables (19/15) (too-many-locals)
parse_gnd.py:285:0: R0912: Too many branches (21/12) (too-many-branches)
parse_gnd.py:285:0: R0915: Too many statements (72/50) (too-many-statements)
parse_gnd.py:434:0: R0914: Too many local variables (18/15) (too-many-locals)
parse_gnd.py:434:0: R0912: Too many branches (21/12) (too-many-branches)
parse_gnd.py:434:0: R0915: Too many statements (76/50) (too-many-statements)
parse_gnd.py:591:11: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd.py:611:11: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd.py:636:11: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd.py:663:24: W0612: Unused variable 'comments' (unused-variable)
parse_gnd.py:665:8: W0612: Unused variable 'name_variant' (unused-variable)
parse_gnd.py:822:16: R0916: Too many boolean expressions in if statement (10/5) (too-many-boolean-expressions)
parse_gnd.py:932:0: R0912: Too many branches (15/12) (too-many-branches)
parse_gnd.py:1030:0: R0912: Too many branches (13/12) (too-many-branches)
parse_gnd.py:1104:0: R0912: Too many branches (13/12) (too-many-branches)
parse_gnd.py:1185:25: W0613: Unused argument 'record' (unused-argument)
parse_gnd.py:1354:11: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd.py:1546:12: W0104: Statement seems to have no effect (pointless-statement)
parse_gnd.py:1546:12: E1101: Method 'append' has no 'subfields' member (no-member)
parse_gnd.py:1575:71: E1101: Instance of 'list' has no 'external_id' member (no-member)
parse_gnd.py:1698:11: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd.py:1718:19: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd.py:7:0: W0611: Unused import os (unused-import)
parse_gnd.py:8:0: W0611: Unused import urllib.request (unused-import)
parse_gnd.py:10:0: W0611: Unused numpy imported as np (unused-import)
parse_gnd.py:11:0: W0611: Unused import pymarc (unused-import)
parse_gnd.py:13:0: W0611: Unused MongoClient imported from pymongo (unused-import)
************* Module bpf_be_fastapi.test_dbactions
test_dbactions.py:7:0: E0401: Unable to import 'classes' (import-error)
test_dbactions.py:8:0: E0401: Unable to import 'db_actions' (import-error)
************* Module bpf_be_fastapi.parse_gnd copy
parse_gnd copy.py:1318:0: C0325: Unnecessary parens after 'return' keyword (superfluous-parens)
parse_gnd copy.py:1450:0: C0325: Unnecessary parens after 'return' keyword (superfluous-parens)
parse_gnd copy.py:1484:0: C0325: Unnecessary parens after 'return' keyword (superfluous-parens)
parse_gnd copy.py:1582:0: C0325: Unnecessary parens after 'return' keyword (superfluous-parens)
parse_gnd copy.py:1687:0: C0325: Unnecessary parens after 'return' keyword (superfluous-parens)
parse_gnd copy.py:1:0: C0103: Module name "parse_gnd copy" doesn't conform to snake_case naming style (invalid-name)
parse_gnd copy.py:16:0: W0622: Redefining built-in 'print' (redefined-builtin)
parse_gnd copy.py:18:0: E0401: Unable to import 'classes' (import-error)
parse_gnd copy.py:19:0: E0401: Unable to import 'db_actions' (import-error)
parse_gnd copy.py:20:0: E0401: Unable to import 'get_external_data' (import-error)
parse_gnd copy.py:21:0: E0401: Unable to import 'parse_date' (import-error)
parse_gnd copy.py:22:0: E0401: Unable to import 'parsing_helpers' (import-error)
parse_gnd copy.py:37:0: R0914: Too many local variables (16/15) (too-many-locals)
parse_gnd copy.py:92:4: W0612: Unused variable 'internal_id_person_type1_needed' (unused-variable)
parse_gnd copy.py:149:8: W0612: Unused variable 'person_found' (unused-variable)
parse_gnd copy.py:283:0: R0914: Too many local variables (19/15) (too-many-locals)
parse_gnd copy.py:283:0: R0912: Too many branches (21/12) (too-many-branches)
parse_gnd copy.py:283:0: R0915: Too many statements (72/50) (too-many-statements)
parse_gnd copy.py:432:0: R0914: Too many local variables (18/15) (too-many-locals)
parse_gnd copy.py:432:0: R0912: Too many branches (21/12) (too-many-branches)
parse_gnd copy.py:432:0: R0915: Too many statements (76/50) (too-many-statements)
parse_gnd copy.py:589:11: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd copy.py:609:11: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd copy.py:634:11: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd copy.py:937:0: R0912: Too many branches (15/12) (too-many-branches)
parse_gnd copy.py:1035:0: R0912: Too many branches (13/12) (too-many-branches)
parse_gnd copy.py:1109:0: R0912: Too many branches (13/12) (too-many-branches)
parse_gnd copy.py:1190:25: W0613: Unused argument 'record' (unused-argument)
parse_gnd copy.py:1359:11: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd copy.py:1551:12: W0104: Statement seems to have no effect (pointless-statement)
parse_gnd copy.py:1551:12: E1101: Method 'append' has no 'subfields' member (no-member)
parse_gnd copy.py:1580:71: E1101: Instance of 'list' has no 'external_id' member (no-member)
parse_gnd copy.py:1703:11: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd copy.py:1723:19: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_gnd copy.py:7:0: W0611: Unused import os (unused-import)
parse_gnd copy.py:8:0: W0611: Unused import urllib.request (unused-import)
parse_gnd copy.py:10:0: W0611: Unused numpy imported as np (unused-import)
parse_gnd copy.py:11:0: W0611: Unused import pymarc (unused-import)
parse_gnd copy.py:13:0: W0611: Unused MongoClient imported from pymongo (unused-import)
************* Module bpf_be_fastapi.main
main.py:25:0: E0401: Unable to import 'parse_iiif' (import-error)
main.py:26:0: E0401: Unable to import 'db_actions' (import-error)
main.py:27:0: E0401: Unable to import 'classes' (import-error)
main.py:28:0: E0401: Unable to import 'image_actions' (import-error)
main.py:29:0: E0401: Unable to import 'book_ingest_create_records' (import-error)
main.py:30:0: E0401: Unable to import 'display_records' (import-error)
main.py:330:26: W0613: Unused argument 'identifier' (unused-argument)
main.py:350:32: W0613: Unused argument 'identifier' (unused-argument)
************* Module bpf_be_fastapi.image_actions
image_actions.py:9:0: E0401: Unable to import 'classes' (import-error)
image_actions.py:10:0: E0401: Unable to import 'db_actions' (import-error)
image_actions.py:21:10: E0601: Using variable 'r' before assignment (used-before-assignment)
image_actions.py:60:0: R0914: Too many local variables (25/15) (too-many-locals)
image_actions.py:60:0: R0915: Too many statements (66/50) (too-many-statements)
************* Module bpf_be_fastapi.parse_vd17_vd18
parse_vd17_vd18.py:53:0: C0303: Trailing whitespace (trailing-whitespace)
parse_vd17_vd18.py:143:0: C0301: Line too long (106/100) (line-too-long)
parse_vd17_vd18.py:180:0: C0301: Line too long (109/100) (line-too-long)
parse_vd17_vd18.py:181:86: C0303: Trailing whitespace (trailing-whitespace)
parse_vd17_vd18.py:194:91: C0303: Trailing whitespace (trailing-whitespace)
parse_vd17_vd18.py:324:44: C0303: Trailing whitespace (trailing-whitespace)
parse_vd17_vd18.py:442:0: C0303: Trailing whitespace (trailing-whitespace)
parse_vd17_vd18.py:535:0: C0303: Trailing whitespace (trailing-whitespace)
parse_vd17_vd18.py:600:0: C0301: Line too long (103/100) (line-too-long)
parse_vd17_vd18.py:7:0: E0401: Unable to import 'classes' (import-error)
parse_vd17_vd18.py:8:0: E0401: Unable to import 'get_external_data' (import-error)
parse_vd17_vd18.py:9:0: E0401: Unable to import 'parsing_helpers' (import-error)
parse_vd17_vd18.py:24:11: I1101: Module 'lxml.etree' has no 'XML' member, but source is unavailable. Consider adding this module to extension-pkg-allow-list if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
parse_vd17_vd18.py:190:16: W0622: Redefining built-in 'id' (redefined-builtin)
parse_vd17_vd18.py:323:16: W0622: Redefining built-in 'id' (redefined-builtin)
parse_vd17_vd18.py:372:12: W0622: Redefining built-in 'id' (redefined-builtin)
parse_vd17_vd18.py:426:16: W0622: Redefining built-in 'id' (redefined-builtin)
************* Module bpf_be_fastapi.parse_date_1
parse_date_1.py:3:0: E0401: Unable to import 'classes' (import-error)
parse_date_1.py:7:0: R0912: Too many branches (31/12) (too-many-branches)
parse_date_1.py:7:0: R0915: Too many statements (197/50) (too-many-statements)
parse_date_1.py:321:4: C0206: Consider iterating with .items() (consider-using-dict-items)
parse_date_1.py:328:0: R0915: Too many statements (77/50) (too-many-statements)
parse_date_1.py:451:0: R0912: Too many branches (32/12) (too-many-branches)
parse_date_1.py:451:0: R0915: Too many statements (155/50) (too-many-statements)
************* Module bpf_be_fastapi.test_main
test_main.py:11:0: E0401: Unable to import 'main' (import-error)
test_main.py:13:0: E0401: Unable to import 'db_actions' (import-error)
************* Module bpf_be_fastapi.parse_iiif
parse_iiif.py:9:0: E0401: Unable to import 'classes' (import-error)
parse_iiif.py:10:0: E0401: Unable to import 'parse_istc' (import-error)
parse_iiif.py:11:0: E0401: Unable to import 'parse_manifests' (import-error)
parse_iiif.py:12:0: E0401: Unable to import 'books_parsing_bibliographies' (import-error)
parse_iiif.py:13:0: E0401: Unable to import 'get_external_data' (import-error)
parse_iiif.py:14:0: E0401: Unable to import 'parse_gnd' (import-error)
parse_iiif.py:15:0: E0401: Unable to import 'parse_vd17_vd18' (import-error)
parse_iiif.py:26:8: R1714: Consider merging these comparisons with 'in' by using 'name in ('VD17', 'vd17')'. Use a set instead if elements are hashable. (consider-using-in)
parse_iiif.py:29:10: R1714: Consider merging these comparisons with 'in' by using 'name in ('VD18', 'vd18')'. Use a set instead if elements are hashable. (consider-using-in)
parse_iiif.py:32:9: R1714: Consider merging these comparisons with 'in' by using 'name in ('VD16', 'vd16')'. Use a set instead if elements are hashable. (consider-using-in)
parse_iiif.py:21:0: R0912: Too many branches (14/12) (too-many-branches)
parse_iiif.py:158:8: W0612: Unused variable 'bib_info' (unused-variable)
************* Module bpf_be_fastapi.book_ingest_create_records
book_ingest_create_records.py:14:0: W0622: Redefining built-in 'print' (redefined-builtin)
book_ingest_create_records.py:16:0: E0401: Unable to import 'db_actions' (import-error)
book_ingest_create_records.py:17:0: E0401: Unable to import 'classes' (import-error)
book_ingest_create_records.py:18:0: E0401: Unable to import 'ingest_organisation' (import-error)
book_ingest_create_records.py:19:0: E0401: Unable to import 'ingest_person' (import-error)
book_ingest_create_records.py:20:0: E0401: Unable to import 'ingest_place' (import-error)
book_ingest_create_records.py:21:0: E0401: Unable to import 'parsing_helpers' (import-error)
book_ingest_create_records.py:22:0: E0401: Unable to import 'parse_gnd' (import-error)
book_ingest_create_records.py:72:8: W0612: Unused variable 'record_id' (unused-variable)
book_ingest_create_records.py:90:0: R0912: Too many branches (19/12) (too-many-branches)
book_ingest_create_records.py:92:4: R1702: Too many nested blocks (7/5) (too-many-nested-blocks)
book_ingest_create_records.py:259:29: W0613: Unused argument 'p' (unused-argument)
book_ingest_create_records.py:265:0: R0912: Too many branches (14/12) (too-many-branches)
book_ingest_create_records.py:267:4: R1702: Too many nested blocks (7/5) (too-many-nested-blocks)
book_ingest_create_records.py:332:0: R0912: Too many branches (19/12) (too-many-branches)
book_ingest_create_records.py:333:4: R1702: Too many nested blocks (7/5) (too-many-nested-blocks)
book_ingest_create_records.py:15:0: W0611: Unused Document imported from beanie (unused-import)
book_ingest_create_records.py:15:0: W0611: Unused Link imported from beanie (unused-import)
************* Module bpf_be_fastapi._books_parsing_manifests_test_
_books_parsing_manifests_test_.py:1:0: C0114: Missing module docstring (missing-module-docstring)
_books_parsing_manifests_test_.py:3:0: E0401: Unable to import 'books_parsing_manifests' (import-error)
_books_parsing_manifests_test_.py:4:0: C0103: Constant name "manifest_default" doesn't conform to UPPER_CASE naming style (invalid-name)
_books_parsing_manifests_test_.py:5:0: C0103: Constant name "entered" doesn't conform to UPPER_CASE naming style (invalid-name)
_books_parsing_manifests_test_.py:9:8: C0103: Constant name "entered" doesn't conform to UPPER_CASE naming style (invalid-name)
************* Module bpf_be_fastapi.get_external_data
get_external_data.py:14:0: E0401: Unable to import 'classes' (import-error)
get_external_data.py:15:0: E0401: Unable to import 'parse_artist_record' (import-error)
get_external_data.py:16:0: E0401: Unable to import 'parsing_helpers' (import-error)
get_external_data.py:46:19: W3101: Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely (missing-timeout)
get_external_data.py:66:12: W1514: Using open without explicitly specifying an encoding (unspecified-encoding)
get_external_data.py:79:8: R1705: Unnecessary "else" after "return", remove the "else" and de-indent the code inside it (no-else-return)
get_external_data.py:66:12: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
get_external_data.py:139:10: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
get_external_data.py:157:0: R0914: Too many local variables (17/15) (too-many-locals)
************* Module bpf_be_fastapi.test_classes
test_classes.py:8:0: E0401: Unable to import 'classes' (import-error)
test_classes.py:9:0: E0401: Unable to import 'db_actions' (import-error)
************* Module bpf_be_fastapi.parse_date
parse_date.py:1:0: C0302: Too many lines in module (1807/1000) (too-many-lines)
parse_date.py:12:0: E0401: Unable to import 'classes' (import-error)
parse_date.py:13:0: E0401: Unable to import 'parsing_helpers' (import-error)
parse_date.py:16:0: R0914: Too many local variables (46/15) (too-many-locals)
parse_date.py:120:31: R1714: Consider merging these comparisons with 'in' by using 'day_string_raw in ('0.', '00.')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:130:13: R1714: Consider merging these comparisons with 'in' by using 'day_string_raw in ('1x.', '2x.')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:176:11: R0916: Too many boolean expressions in if statement (6/5) (too-many-boolean-expressions)
parse_date.py:176:11: R1714: Consider merging these comparisons with 'in' by using 'suffix_raw in ('v.chr.', 'v. chr.', 'jh.v.chr.', 'jh. v.chr.', 'jh. v. chr.', 'jh.v.chr')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:245:13: R0916: Too many boolean expressions in if statement (6/5) (too-many-boolean-expressions)
parse_date.py:361:23: R1714: Consider merging these comparisons with 'in' by using 'part_number in ('1.', '1 ', 'erste ')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:364:23: R1714: Consider merging these comparisons with 'in' by using 'part_number in ('2.', '2 ')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:368:23: R1714: Consider merging these comparisons with 'in' by using 'part_number in ('1.', '1 ')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:371:23: R1714: Consider merging these comparisons with 'in' by using 'part_number in ('2.', '2 ')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:375:23: R1714: Consider merging these comparisons with 'in' by using 'part_number in ('3.', '3 ', 'letztes ')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:379:23: R1714: Consider merging these comparisons with 'in' by using 'part_number in ('1.', '1 ', 'erstes ')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:382:23: R1714: Consider merging these comparisons with 'in' by using 'part_number in ('2.', '2 ')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:386:23: R1714: Consider merging these comparisons with 'in' by using 'part_number in ('3.', '3 ')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:390:23: R1714: Consider merging these comparisons with 'in' by using 'part_number in ('4.', 'letztes ')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:545:59: E0606: Possibly using variable 'day_value_start' before assignment (possibly-used-before-assignment)
parse_date.py:546:36: E0606: Possibly using variable 'month_value_end' before assignment (possibly-used-before-assignment)
parse_date.py:16:0: R0912: Too many branches (87/12) (too-many-branches)
parse_date.py:16:0: R0915: Too many statements (428/50) (too-many-statements)
parse_date.py:16:0: R1710: Either all return statements in a function should return an expression, or none of them should. (inconsistent-return-statements)
parse_date.py:552:0: R0914: Too many local variables (101/15) (too-many-locals)
parse_date.py:609:25: W0109: Duplicate key '–' in dictionary (duplicate-key)
parse_date.py:666:11: R0916: Too many boolean expressions in if statement (12/5) (too-many-boolean-expressions)
parse_date.py:705:11: R0916: Too many boolean expressions in if statement (12/5) (too-many-boolean-expressions)
parse_date.py:838:15: R1714: Consider merging these comparisons with 'in' by using 'date_indicator in ('datl', 'datx')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:840:15: R1714: Consider merging these comparisons with 'in' by using 'date_indicator in ('datw', 'datz')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:846:12: R1730: Consider using 'start_start_date = min(start_start_date, start_alternative_start_date)' instead of unnecessary if block (consider-using-min-builtin)
parse_date.py:849:12: R1731: Consider using 'end_end_date = max(end_end_date, end_alternative_end_date)' instead of unnecessary if block (consider-using-max-builtin)
parse_date.py:853:11: R1716: Simplify chained comparison between the operands (chained-comparison)
parse_date.py:853:60: E0601: Using variable 'end_start_date' before assignment (used-before-assignment)
parse_date.py:858:11: E0601: Using variable 'start_short' before assignment (used-before-assignment)
parse_date.py:858:27: E0601: Using variable 'end_short' before assignment (used-before-assignment)
parse_date.py:858:42: R1714: Consider merging these comparisons with 'in' by using 'end_aspect in (start_aspect, '')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:870:20: W0104: Statement seems to have no effect (pointless-statement)
parse_date.py:836:4: R1702: Too many nested blocks (6/5) (too-many-nested-blocks)
parse_date.py:893:15: R1714: Consider merging these comparisons with 'in' by using 'date_indicator in ('datl', 'datx')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:895:15: R1714: Consider merging these comparisons with 'in' by using 'date_indicator in ('datw', 'datz')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:907:12: R1730: Consider using 'start_start_date = min(start_start_date, start_alternative_start_date)' instead of unnecessary if block (consider-using-min-builtin)
parse_date.py:910:12: R1731: Consider using 'start_end_date = max(start_end_date, start_alternative_end_date)' instead of unnecessary if block (consider-using-max-builtin)
parse_date.py:921:15: R1714: Consider merging these comparisons with 'in' by using 'date_indicator in ('datl', 'datx')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:923:15: R1714: Consider merging these comparisons with 'in' by using 'date_indicator in ('datw', 'datz')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:929:16: W0104: Statement seems to have no effect (pointless-statement)
parse_date.py:932:12: R1730: Consider using 'end_start_date = min(end_start_date, end_alternative_start_date)' instead of unnecessary if block (consider-using-min-builtin)
parse_date.py:935:12: R1731: Consider using 'end_end_date = max(end_end_date, end_alternative_end_date)' instead of unnecessary if block (consider-using-max-builtin)
parse_date.py:945:15: R1714: Consider merging these comparisons with 'in' by using 'date_indicator in ('datl', 'datx')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:947:15: R1714: Consider merging these comparisons with 'in' by using 'date_indicator in ('datw', 'datz')'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:955:12: R1730: Consider using 'only_start_date = min(only_start_date, only_alternative_start_date)' instead of unnecessary if block (consider-using-min-builtin)
parse_date.py:958:12: R1731: Consider using 'only_end_date = max(only_end_date, only_alternative_end_date)' instead of unnecessary if block (consider-using-max-builtin)
parse_date.py:552:0: R0912: Too many branches (101/12) (too-many-branches)
parse_date.py:552:0: R0915: Too many statements (345/50) (too-many-statements)
parse_date.py:552:35: W0613: Unused argument 'date_comments' (unused-argument)
parse_date.py:698:12: W0612: Unused variable 'start_precision' (unused-variable)
parse_date.py:738:12: W0612: Unused variable 'end_precision' (unused-variable)
parse_date.py:797:16: W0612: Unused variable 'end_type' (unused-variable)
parse_date.py:810:20: W0612: Unused variable 'only_short' (unused-variable)
parse_date.py:812:20: W0612: Unused variable 'only_precision' (unused-variable)
parse_date.py:972:0: R0914: Too many local variables (31/15) (too-many-locals)
parse_date.py:972:0: R0912: Too many branches (34/12) (too-many-branches)
parse_date.py:972:0: R0915: Too many statements (189/50) (too-many-statements)
parse_date.py:1212:0: R0914: Too many local variables (37/15) (too-many-locals)
parse_date.py:1279:63: E0601: Using variable 'start_datestring' before assignment (used-before-assignment)
parse_date.py:1282:33: E0606: Possibly using variable 'start_start' before assignment (possibly-used-before-assignment)
parse_date.py:1283:31: E0606: Possibly using variable 'start_end' before assignment (possibly-used-before-assignment)
parse_date.py:1293:51: E0601: Using variable 'end_datestring' before assignment (used-before-assignment)
parse_date.py:1294:31: E0606: Possibly using variable 'end_end' before assignment (possibly-used-before-assignment)
parse_date.py:1296:33: E0606: Possibly using variable 'end_start' before assignment (possibly-used-before-assignment)
parse_date.py:1305:19: R1716: Simplify chained comparison between the operands (chained-comparison)
parse_date.py:1307:19: E0606: Possibly using variable 'start_short' before assignment (possibly-used-before-assignment)
parse_date.py:1307:35: E0606: Possibly using variable 'end_short' before assignment (possibly-used-before-assignment)
parse_date.py:1246:4: R1702: Too many nested blocks (6/5) (too-many-nested-blocks)
parse_date.py:1320:27: E0606: Possibly using variable 'start_type' before assignment (possibly-used-before-assignment)
parse_date.py:1246:4: R1702: Too many nested blocks (6/5) (too-many-nested-blocks)
parse_date.py:1330:27: E0606: Possibly using variable 'end_type' before assignment (possibly-used-before-assignment)
parse_date.py:1246:4: R1702: Too many nested blocks (6/5) (too-many-nested-blocks)
parse_date.py:1365:19: E0606: Possibly using variable 'single_type' before assignment (possibly-used-before-assignment)
parse_date.py:1366:39: E0606: Possibly using variable 'single_datestring' before assignment (possibly-used-before-assignment)
parse_date.py:1370:33: E0606: Possibly using variable 'single_start' before assignment (possibly-used-before-assignment)
parse_date.py:1371:31: E0606: Possibly using variable 'single_end' before assignment (possibly-used-before-assignment)
parse_date.py:1212:0: R0912: Too many branches (66/12) (too-many-branches)
parse_date.py:1212:0: R0915: Too many statements (196/50) (too-many-statements)
parse_date.py:1436:0: R0914: Too many local variables (32/15) (too-many-locals)
parse_date.py:1638:8: R1714: Consider merging these comparisons with 'in' by using 'month_start in (4, 6, 9, 11)'. Use a set instead if elements are hashable. (consider-using-in)
parse_date.py:1436:0: R0912: Too many branches (42/12) (too-many-branches)
parse_date.py:1436:0: R0915: Too many statements (180/50) (too-many-statements)
parse_date.py:1501:8: W0612: Unused variable 'month_indicated' (unused-variable)
parse_date.py:1509:8: W0612: Unused variable 'day_indicated' (unused-variable)
parse_date.py:1658:0: R0914: Too many local variables (36/15) (too-many-locals)
parse_date.py:1694:7: E0601: Using variable 'date_formatted_0' before assignment (used-before-assignment)
parse_date.py:1697:11: E0606: Possibly using variable 'date_active_0' before assignment (possibly-used-before-assignment)
parse_date.py:1699:13: E0606: Possibly using variable 'date_died_0' before assignment (possibly-used-before-assignment)
parse_date.py:1703:35: E0606: Possibly using variable 'date_start_0' before assignment (possibly-used-before-assignment)
parse_date.py:1704:33: E0606: Possibly using variable 'date_end_0' before assignment (possibly-used-before-assignment)
parse_date.py:1709:29: E0606: Possibly using variable 'date_died_1' before assignment (possibly-used-before-assignment)
parse_date.py:1716:33: E0606: Possibly using variable 'date_end_1' before assignment (possibly-used-before-assignment)
parse_date.py:1721:29: E0606: Possibly using variable 'date_died_2' before assignment (possibly-used-before-assignment)
parse_date.py:1726:33: E0606: Possibly using variable 'date_end_2' before assignment (possibly-used-before-assignment)
parse_date.py:1754:33: E0606: Possibly using variable 'date_end_3' before assignment (possibly-used-before-assignment)
parse_date.py:1771:7: E0606: Possibly using variable 'daterange_complete_start' before assignment (possibly-used-before-assignment)
parse_date.py:1771:34: E0606: Possibly using variable 'daterange_complete_end' before assignment (possibly-used-before-assignment)
parse_date.py:1776:26: E0606: Possibly using variable 'date_complete' before assignment (possibly-used-before-assignment)
parse_date.py:1658:0: R0912: Too many branches (41/12) (too-many-branches)
parse_date.py:1658:0: R0915: Too many statements (112/50) (too-many-statements)
parse_date.py:1678:26: W0612: Unused variable 'date_active_1' (unused-variable)
parse_date.py:1678:54: W0612: Unused variable 'date_start_1' (unused-variable)
parse_date.py:1684:26: W0612: Unused variable 'date_active_2' (unused-variable)
parse_date.py:1684:54: W0612: Unused variable 'date_start_2' (unused-variable)
parse_date.py:1690:26: W0612: Unused variable 'date_active_3' (unused-variable)
parse_date.py:1690:41: W0612: Unused variable 'date_died_3' (unused-variable)
parse_date.py:1690:54: W0612: Unused variable 'date_start_3' (unused-variable)
************* Module bpf_be_fastapi.parse_istc
parse_istc.py:272:0: C0301: Line too long (157/100) (line-too-long)
parse_istc.py:6:0: E0401: Unable to import 'classes' (import-error)
parse_istc.py:7:0: E0401: Unable to import 'get_external_data' (import-error)
parse_istc.py:47:0: C0116: Missing function or method docstring (missing-function-docstring)
parse_istc.py:47:0: R0914: Too many local variables (26/15) (too-many-locals)
parse_istc.py:70:16: E0602: Undefined variable 'bi' (undefined-variable)
parse_istc.py:70:32: E0602: Undefined variable 'bi' (undefined-variable)
parse_istc.py:70:47: E0602: Undefined variable 'bi' (undefined-variable)
parse_istc.py:107:40: E0602: Undefined variable 'bi' (undefined-variable)
parse_istc.py:109:20: E0602: Undefined variable 'bi' (undefined-variable)
parse_istc.py:151:28: E0602: Undefined variable 'bi' (undefined-variable)
parse_istc.py:156:24: E0602: Undefined variable 'bi' (undefined-variable)
parse_istc.py:51:4: R1702: Too many nested blocks (9/5) (too-many-nested-blocks)
parse_istc.py:193:28: E0602: Undefined variable 'bi' (undefined-variable)
parse_istc.py:201:24: E0602: Undefined variable 'bi' (undefined-variable)
parse_istc.py:51:4: R1702: Too many nested blocks (9/5) (too-many-nested-blocks)
parse_istc.py:202:22: E0602: Undefined variable 'istc_record_short' (undefined-variable)
parse_istc.py:203:12: E0602: Undefined variable 'bi' (undefined-variable)
parse_istc.py:203:23: E0602: Undefined variable 'istc_record_short' (undefined-variable)
parse_istc.py:206:11: E0602: Undefined variable 'bi' (undefined-variable)
parse_istc.py:47:0: R0912: Too many branches (27/12) (too-many-branches)
parse_istc.py:47:0: R0915: Too many statements (88/50) (too-many-statements)
parse_istc.py:259:0: R0914: Too many local variables (28/15) (too-many-locals)
parse_istc.py:259:0: R0915: Too many statements (53/50) (too-many-statements)
parse_istc.py:488:15: R1714: Consider merging these comparisons with 'in' by using 'date_prefix in ('About ', 'about ')'. Use a set instead if elements are hashable. (consider-using-in)
parse_istc.py:434:0: R0912: Too many branches (13/12) (too-many-branches)
parse_istc.py:547:0: R0913: Too many arguments (6/5) (too-many-arguments)
parse_istc.py:547:0: R0912: Too many branches (14/12) (too-many-branches)
************* Module bpf_be_fastapi.test_parse_manifests
test_parse_manifests.py:5:0: W0622: Redefining built-in 'print' (redefined-builtin)
test_parse_manifests.py:9:0: E0401: Unable to import 'db_actions' (import-error)
test_parse_manifests.py:10:0: E0401: Unable to import 'parse_manifests' (import-error)
test_parse_manifests.py:11:0: E0401: Unable to import 'get_external_data' (import-error)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[216:660]
==bpf_be_fastapi.parse_gnd:[218:662]
        name_divided = person_name_search.split("%20")
        name_query = ""
        for word in name_divided:
            if word != "": #necessary, otherwise there will be error messages
                search_phrase = r"Per=" + word + r"%20and%20" # I don't get it, but the thing only works if the "=" is written as such and not as Percent code. Above, it is different.
                name_query = name_query + search_phrase
        authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=' + name_query + r'BBG%3DTp*&recordSchema=MARC21-xml&maximumRecords=100'
#        print(authority_url)
        new_potential_candidates = await find_and_parse_person_gnd(authority_url)
        role_in.entity_and_connections.connected_entities = new_potential_candidates

#        role_in.entity_and_connections.connected_persons.ap
#                = new_potential_candidates
#        person_in.person_candidates = person.person_candidates + new_potential_candidates
#         else:
#             if not person_in.person_candidates:
#                 person = await get_external_data.search_ulan(person)
#     if len(person_in.person_candidates) == 1: # If there is only one entry for this person, it is by default selected (although the user can also run a new search, once this is established)
#         person.chosen_candidate = 0
#     print("new person record")
# #    print(person)
#     person_in.person=person
#    print(person)
    print(role_in.model_dump())
    return role_in




@classes.async_func_logger
async def identify_additional_person(new_authority_id, role):
    """
This function is used for any additional authority records that are suggested as identifications for persons connected to a book.
Normally, they are parsed with gnd_parsing_person - but beforehand it is checked if they are already in Iconobase and have not been found for whatever reason.
Currently all records must come from the GND - if other authority files are included, this function has to be changed.
    """
    new_authority_id = new_authority_id.strip()
    potential_persons_list = []
    potential_person = classes.Node()
#    person_found = coll.find_one({"external_id": {"$elemMatch": {"name": "GND", "id": new_authority_id}}}, {"id": 1, "person_type1": 1, "name_preferred": 1})
    person = classes.Node()
    person.new_authority_id = new_authority_id
    person_found = db_actions.find_person(person,"GND")
    if person_found:
        #print(person_found)
        potential_person.internal_id = person_found["id"]
        potential_person.internal_id_person_type1 = person_found["person_type1"]
        potential_person.preview = person_found["name_preferred"] # The date should be added, but I first have to write how it is to be parsed
        internal_id_person_type1_needed =  parsing_helpers.map_role_to_person_type(role)
        if internal_id_person_type1_needed not in potential_person.internal_id_person_type1:
            person_type1_present = ""
            for t in potential_person.internal_id_person_type1:
                person_type1_present = person_type1_present + "' and '" + t + "'"
            person_type1_present = person_type1_present[5:]
            potential_person.internal_id_person_type1_comment = "This person is currently catalogued as " + person_type1_present + ", but not as '" \
                + internal_id_person_type1_needed + "'. The latter will be added if this record has been saved. "
        potential_persons_list.append(potential_person)

    else:
        authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + new_authority_id + r'%20and%20BBG%3DTp*&recordSchema=MARC21-xml&maximumRecords=100'
        potential_persons_list = await find_and_parse_person_gnd(authority_url)
    #print("added person")
    #print(potential_persons_list)
    return potential_persons_list

@classes.func_logger
def identify_organisation(organisation):
    """
This function is used for every organisation named in the bibliographic record (printer etc.),
 and in addition for the repository of a book or manuscript. It will first search if a record
   for this organisation is already in the MongoDB database, and then search in the GND. If
   there is an ID-number (internal or GND, the search is done for the ID-number, otherwise for
     the name as string, and if this fails, for the name as key-words)
    """
#    candidates = []
    print("Starting organisatin_identification for repository")
    organisation.internal_id_org_type1_needed = parsing_helpers.map_role_to_organisation_type(organisation.role)
    organisation.chosen_candidate = 999 # For some reason, this must not be empty
    if organisation.id:
#        organisation_found = coll.find_one({"external_id": {"$elemMatch": {"name": organisation.id_name, "id": organisation.id}}}, {"id": 1, "name_preferred": 1, "org_type1": 1})
        organisation_found = db_actions.find_organisation(organisation,"external_id")
        if organisation_found:
            organisation.internal_id = organisation_found["id"]
            organisation.internal_id_preview = organisation_found["name_preferred"] + " (in Database)"
            organisation.internal_id_org_type1 = organisation_found["org_type1"]
            org_type1_needed =  parsing_helpers.map_role_to_organisation_type(organisation.role)

            #The following is a warning that a matching person has the wrong type.
            if org_type1_needed not in organisation.internal_id_org_type1:
                org_type1_present = ""
                for t in organisation.internal_id_org_type1:
                    org_type1_present = org_type1_present + "' and '" + t
                    org_type1_present = org_type1_present[5:] + "'"
                organisation.internal_id_org_type1_comment = "This organisation is currently catalogued as " + org_type1_present + ", but not as '" + org_type1_needed + "'. The latter will be added if this record has been saved. "

        else:
            if organisation.id_name == "GND": # I will have to create similar things for other authority files
                authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + organisation.id + r'%20and%20BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100'
                print(authority_url)
                organisation.potential_candidates = find_and_parse_organisation_gnd(authority_url)
    else:
        print("No repository ID")
        organisation.name = organisation.name.strip()
#        candidates_result = (coll.find({"name_preferred" : organisation.name}, {"id": 1, "name_preferred" : 1, "org_type1" : 1}))
        candidates_result = db_actions.find_organisation(organisation,"name")
        print("Search for repository candidate completed")
        for candidate_result in candidates_result:
            candidate = classes.Node()
            candidate.internal_id = candidate_result["id"]
            candidate.name_preferred = candidate_result["name_preferred"]
            candidate.preview = candidate_result["name_preferred"] + " (in Database)"
            candidate.internal_id_org_type1 = candidate_result["org_type1"]
            print("orgtype1 in search for name_preferred: ")
            print(candidate.preview)
            print(candidate.internal_id_org_type1)
            organisation.potential_candidates.append(candidate)
#        candidates_result = coll.find({"name_variant" : organisation.name}, {"id": 1, "name_preferred" : 1, "org_type1" : 1}) #I search first for the preferred names (assuming that it is more likely there will be a good match, and only later for the variants)
        candidates_result = db_actions.find_organisation(organisation,"name_variant")
        for candidate_result in candidates_result:
            candidate = classes.Node()
            candidate.internal_id = candidate_result["id"]
            candidate.name_preferred = candidate_result["name_preferred"]
            candidate.internal_id_org_type1 = candidate_result["org_type1"]
            candidate.preview = candidate.name_preferred + " (in Database)" # Maybe I add other information to it later.
            print("orgtype1 in search for name_variant: ")
            print(candidate.internal_id_org_type1)
            candidate_duplicate = False # This is needed to avoid having a candidate listed twice, it is rather longwided since I cannot use a simple if ... in thing in class instances.
            for extant_candidate in organisation.potential_candidates:
                if extant_candidate.name_preferred == candidate.name_preferred:
                    candidate_duplicate = True
            if not candidate_duplicate:

#            if candidate not in organisation.potential_candidates:
#                print("Candidate not yet in list")
                organisation.potential_candidates.append(candidate)
            # The following is about a warning if the found organisations have the wrong type. I could not try it out, since the VD17 always gives IDs of organisations,
            # and the ISTC does not have them.
            for candidate in organisation.potential_candidates:
                print("Repository types present:")
                print(candidate.internal_id_org_type1)
                print("Repository types needed: ")
                print(organisation.internal_id_org_type1_needed)
                if organisation.internal_id_org_type1_needed not in candidate.internal_id_org_type1:
                    org_type1_present = ""
                    for t in candidate.internal_id_org_type1:
                        org_type1_present = org_type1_present + "' and '" + t + "'"
                    org_type1_present = org_type1_present[5:]
                    candidate.internal_id_org_type1_comment = "This organisation is currently catalogued as "\
                          + org_type1_present + ", but not as '" + organisation.internal_id_org_type1_needed + "'. The latter will be added if this record has been saved. "

        if not organisation.potential_candidates: #if nothing has been found in the database
            organisation_name_search = organisation.name
            for old, new in parsing_helpers.url_replacement.items():
                organisation_name_search = organisation_name_search.replace(old, new)
            authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=Koe%3D' + organisation_name_search + r'%20and%20BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100'
            organisation.potential_candidates = find_and_parse_organisation_gnd(authority_url)
            name_divided = organisation_name_search.split("%20")
            name_query = ""
            for word in name_divided:
                if word != "":
                    search_phrase = r"Koe=" + word + r"%20and%20" # I don't get it, but the thing only works if the "=" is written as such and not as Percent code. Above, it is different.
                    name_query = name_query + search_phrase
#                    print ("name query:" + name_query)
            authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=' + name_query + r'BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100'

            new_potential_candidates = find_and_parse_organisation_gnd(authority_url)
            for candidate in new_potential_candidates:
                if candidate not in organisation.potential_candidates: #I need this distinction because I perform both a string and a keyword search, and both may yield the same results
                    organisation.potential_candidates.append(candidate)
    if len(organisation.potential_candidates) == 1: # If there is only one entry for this organisation, it is by default selected (although the user can also run a new search, once this is established)
        organisation.chosen_candidate = 0

    return organisation

@classes.func_logger
def identify_additional_organisation(new_authority_id, role):
    """
This function is used for any additional authority records that are suggested as identifications for organisations connected to a book.
Normally, they are parsed with gnd_parsing_organisation - but beforehand it is checked if they are already in Iconobase and have not been found for whatever reason.
Currently all records must come from the GND - if other authority files are included, this function has to be changed.
    """
    new_authority_id = new_authority_id.strip()
    potential_orgs_list = []
    potential_org = classes.Node()
    org = classes.Node()
    org.new_authority_id=new_authority_id
#    org_found = coll.find_one({"external_id": {"$elemMatch": {"name": "GND", "id": new_authority_id}}}, {"id": 1, "name_preferred": 1, "org_type1" : 1})
    org_found = db_actions.find_organisation(org,"GND")
    if org_found:
        print(org_found)
        potential_org.internal_id = org_found["id"]
        potential_org.internal_id_org_type1 = org_found["org_type1"]
        potential_org.preview = org_found["name_preferred"] # The date should be added, but I first have to write how it is to be parsed
        internal_id_org_type1_needed = parsing_helpers.map_role_to_organisation_type(role)
        if internal_id_org_type1_needed not in potential_org.internal_id_org_type1:
            org_type1_present = ""
            for t in potential_org.internal_id_org_type1:
                org_type1_present = org_type1_present + "' and '" + t + "'"
            org_type1_present = org_type1_present[5:]
            potential_org.internal_id_org_type1_comment = "This organisation is currently catalogued as " + org_type1_present + ", but not as '" \
                + internal_id_org_type1_needed + "'. The latter will be added if this record has been saved. "
        else:
            internal_id_org_type1_needed = ""
        potential_orgs_list.append(potential_org)
    else:
        authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + new_authority_id + r'%20and%20BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100'
        potential_orgs_list = find_and_parse_organisation_gnd(authority_url)

    return potential_orgs_list





@classes.func_logger
async def identify_place(place):
    """
This function is used for every place named in the bibliographic record (place of publishing / manufacture)
It will first search if a record for this place is already in the MongoDB database, and then search in the GND
If there is an ID-number (internal or GND, the search is done for the ID-number, otherwise for the name as string, and if this fails, for the name as key-words)
Note that the GND parser combined with it suppresses all records to regions - if this mechanism is later also used for identifying regions, this might need to be changed
Since there are often many locations connected toa town (e.g., all villages in its district), I increase the number of hits from the GND to 400 and sort them alphabetically.
    """
    if place.role:
        print(place.role)
    else:
        print("No place.role")
        place.role = "pup" # I just define this for the time being.
    place.internal_id_place_type1_needed = parsing_helpers.map_role_to_place_type(place.role)
    place.chosen_candidate = 999
    print("Arrived in place_identification")
    if place.id:
#        place_found = coll.find_one({"external_id": {"$elemMatch": {"name": place.id_name, "id": place.id}}}, {"id": 1, "name_preferred": 1, "place_type1" : 1})
        place_found = db_actions.find_place(place,"external_id")
        if place_found:
            place.internal_id = place_found["id"]
            place.internal_id_preview = place_found["name_preferred"] + " (in Database)"
            place.internal_id_place_type1 = place_found["place_type1"]
#            print('Place data:')
#            print(place.internal_id_place_type1)
            place_type1_needed = parsing_helpers.map_role_to_place_type(place.role)
            #The following is a warning that a matching place has the wrong type. It should also be
            # included for all searches for names in Iconobase, but I don't build this yet since there aren't any records in it that allow my to try it out.
            # This option has not been tried out properly since places rarely come with GND numbers
            if place_type1_needed not in place.internal_id_place_type1:
                place_type1_present = ""
                for t in place.internal_id_place_type1:
                    place_type1_present = place_type1_present + "' and '" + t
                place_type1_present = place_type1_present[5:] + "'"

                place.internal_id_place_type1_comment = "This place is currently catalogued as " + place_type1_present + ", but not as '" + place_type1_needed + "'. \
                    An additional record for " + place_type1_needed + " will be produced if this record is saved. "
        else:
            if place.id_name == "GND": # I will have to create similar things for other authority files
                authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + place.id + r'%20and%20BBG%3DTg*&recordSchema=MARC21-xml&maximumRecords=100'
                print("authority_url with Gnd number: " + authority_url)
                place.potential_candidates = await parse_place_gnd(authority_url)
    else:
        print("place name has no ID")
        place.name = place.name.strip()
#        candidates_result = coll.find({"name_preferred" : place.name}, {"id": 1, "name_preferred" : 1, "place_type1" : 1})
        candidates_result = db_actions.find_place(place,"name_preferred")
        for candidate_result in candidates_result:
            candidate = classes.Node()
            candidate.internal_id = candidate_result["id"]
            candidate.name_preferred = candidate_result["name_preferred"] # I need this to create previews for places of making
            print("candidate found through name search in database (preferred name)" + candidate.internal_id)
            candidate.preview = candidate_result["name_preferred"] + " (in Database)"
            candidate.internal_id_place_type1 = candidate_result["place_type1"]
            place.potential_candidates.append(candidate)
#        candidates_result = coll.find({"name_variant" : place.name}, {"id": 1, "name_preferred" : 1, "place_type1" : 1}) #I search first for the preferred names (assuming that it is more likely there will be a good match, and only later for the variants)
        candidates_result = db_actions.find_place(place,"name_variant")
        for candidate_result in candidates_result:
            candidate = classes.Node()
            candidate.internal_id = candidate_result["id"]
            print("candidate found through name search in database (variant name name)" + candidate.internal_id)
            candidate.preview = candidate_result["name_preferred"] + " (in Database)"
            candidate.internal_id_place_type1 = candidate_result["place_type1"]

            if candidate not in place.potential_candidates:
                place.potential_candidates.append(candidate)
                # Warning if the place has not the right type:
            for candidate in place.potential_candidates:
                print(candidate.preview)
                print(candidate.internal_id_place_type1)
                print(place.internal_id_place_type1_needed)
                if place.internal_id_place_type1_needed not in candidate.internal_id_place_type1:
                    place_type1_present = ""
                    for t in candidate.internal_id_place_type1:
                        place_type1_present = place_type1_present + "' and '" + t + "'"
                    place_type1_present = place_type1_present[5:]


                    candidate.internal_id_place_type1_comment = "This place is currently catalogued as " + place_type1_present + ", but not as '" + place.internal_id_place_type1_needed + "'. \
                    An additional record for " + place.internal_id_place_type1_needed + " will be produced if this place is selected and the record is saved. "

        if not place.potential_candidates: #if nothing has been found
            print("Candidate not found in database")
            place_name_search = place.name.strip()
            for old, new in parsing_helpers.url_replacement.items():
                place_name_search = place_name_search.replace(old, new)
                #print("Search term for place :x" + place_name_search + "x")
            authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=Geo%3D' + place_name_search + r'%20and%20BBG%3DTg*&recordSchema=MARC21-xml&maximumRecords=100'
            print('URL for place name search : '+ authority_url)
            place.potential_candidates = await parse_place_gnd(authority_url)
            print("Number of 'portential candidates': ")
            print(len(place.potential_candidates))
#       I actually do not believe that one needs a words search for places
            name_divided = place_name_search.split("%20")
            name_query = ""
            for word in name_divided:
                if word != "":
                    search_phrase = r"Geo%3D" + word + r"%20and%20" # I don't get it, but the thing only works if the "=" is written as such and not as Percent code. Above, it is different.
                    name_query = name_query + search_phrase
                    print ("name query:" + name_query)
            authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=' + name_query + r'BBG%3DTg*&recordSchema=MARC21-xml&maximumRecords=100'
            additional_potential_candidates = await parse_place_gnd(authority_url)
            print("Number or additional potential candidates: ")
            print(len(additional_potential_candidates))
            for additional_candidate in additional_potential_candidates:
                if additional_candidate not in place.potential_candidates:
                    place.potential_candidates.append(additional_candidate)
    place.potential_candidates = sorted(place.potential_candidates, key = lambda candidate : candidate.preview)
    if len(place.potential_candidates) == 1: # If there is only one entry for this person, it is by default selected (although the user can also run a new search, once this is established)
        place.chosen_candidate = 0
    return place


@classes.func_logger
async def identify_additional_place(new_authority_id, role):
    """
This function is used for any additional authority records that are suggested as identifications for organisations connected to a book.
Normally, they are parsed with gnd_parsing_place - but beforehand it is checked if they are already in Iconobase and have not been found for whatever reason.
Currently all records must come from the GND - if other authority files are included, this function has to be changed.
    """
    new_authority_id = new_authority_id.strip()
    potential_places_list = []
    potential_place = classes.Node()
#    place_found = coll.find_one({"external_id": {"$elemMatch": {"name": "GND", "id": new_authority_id}}}, {"id": 1, "name_preferred": 1, "place_type1" : 1})
    place=classes.Node
    place.new_authority_id=new_authority_id
    place_found = db_actions.find_place(place,"GND")
    if place_found:
#        print(place_found)
        potential_place.internal_id = place_found["id"]
        potential_place.internal_id_place_type1 = place_found["place_type1"]
        potential_place.preview = place_found["name_preferred"] + " (in Database)"
        internal_id_place_type1_needed = parsing_helpers.map_role_to_place_type(role)
        if internal_id_place_type1_needed not in potential_place.internal_id_place_type1:
            place_type1_present = ""
            for t in potential_place.internal_id_place_type1:
                place_type1_present = place_type1_present + "' and '" + t + "'"
            place_type1_present = place_type1_present[5:]
            potential_place.internal_id_place_type1_comment = "This place is currently catalogued as " + place_type1_present + ", but not as '" \
                + internal_id_place_type1_needed + "'. An additional record for " + internal_id_place_type1_needed + " will be produced if this place is selected and the record is saved. "
        potential_places_list.append(potential_place)
    else:
        authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + new_authority_id + r'%20and%20BBG%3DTg*&recordSchema=MARC21-xml&maximumRecords=100'
#        print("authority URL in additional_place_identification")
#        print(authority_url)
        potential_places_list = await parse_place_gnd(authority_url)
#        print("Potential places list in additional_place_identification: ")
#        print(potential_places_list)
    return potential_places_list


@classes.async_func_logger
async def find_and_parse_person_gndid(gnd_id):
    authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D'\
                    + gnd_id\
                    + r'%20and%20BBG%3DTp*&recordSchema=MARC21-xml&maximumRecords=100'
    content=await get_external_data.get_web_data(authority_url)
    root = etree.XML(content)
    records=root.find("records", namespaces=root.nsmap)
    for record in records:
#Set GND IDs
        d = find_datafields(record,"035")
#        print(x)
        s = find_subfields(d,"a")
        for y in s:
            if y.get("a") is not None:
                external_reference = classes.ExternalReference()
                external_reference.name="GND"
                external_reference.external_id=y["a"]
#                person_found.external_id.append(external_reference)

@classes.async_func_logger
async def get_records(gnd_id):
    authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D'\
                    + gnd_id\
                    + r'%20and%20BBG%3DTp*&recordSchema=MARC21-xml&maximumRecords=100'
    content=await get_external_data.get_web_data(authority_url)
    root = etree.XML(content)
    records=root.find("records", namespaces=root.nsmap)
    return records

@classes.async_func_logger
async def find_related_persons(gnd_id):
    records = await get_records(gnd_id)
    for record in records:
        r = gnd_record_get_connected_persons(record)
    return r



@classes.async_func_logger
async def find_and_parse_person_gnd(authority_url):
    """
\todo
    """

#    url = urllib.request.urlopen(authority_url)
#    tree = xml.etree.ElementTree.parse(url)
#    root = tree.getroot()

    result = []
    content=await get_external_data.get_web_data(authority_url)
    root = etree.XML(content)
    records=root.find("records", namespaces=root.nsmap)
#    print(records)
#    print(records.tag)
#    tag_id='400'
#    subfield_code="a"
    for record in records:
        print("found record")



    #print(root)

    # for record in root[2]:
    #     print("Parsing person information")
    #     pe = classes.Person()
    #     comment = ""
    #     date_preview = ""
    #     ortg_preview = ""
    #     orts_preview = ""
    #     ortw_preview = ""
    #     name_variant_preview = ""
    #     comments_preview = ""

        person_found=classes.Node()
        person_found.external_id.extend(gnd_record_get_gnd_internal_id(record))
        person_found.external_id.extend(gnd_record_get_external_references(record)) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[844:1879]
==bpf_be_fastapi.parse_gnd:[841:1874]
    return (name_preferred, comments)
#    person_found.name_preferred = name_preferred
#    print(name_preferred)

@classes.func_logger
def gnd_record_get_sex(record):
    """
    #                 case "375":
    #                     for step2 in step1:
    #                         match step2.get('code'):
    #                             case "a":
    #                                 if step2.text == "1":
    #                                     pe.sex = "male"
    #                                 if step2.text == "2":
    #                                     pe.sex = "female"
    # Set sex
    """
    print("in function gnd_record_get_sex")
    sex = ""
    datafields = find_datafields(record,"375")
    for datafield in datafields:

        subfields = find_subfields(datafield,"a")
        if subfields:
            print("sex_subfields")
            print(subfields)
            if subfields[0] == "1":
                sex = "male"
            elif subfields[0] == "2":
                sex = "female"
    return sex


@classes.func_logger
def gnd_record_get_name_variant(record, comments):
    """
#                 case "400":
#                     name_number = ""
#                     name_comment = ""
#                     for step2 in step1:
#                         match step2.get('code'):
#                             case "a":
#                                 name_variant = step2.text
#                             case "b": # The numbering for rulers
#                                 name_number =  " " + step2.text
#                             case "c": # For rulers, comments on Territory, title and time of ruling.
#                                 # I put that now into a comment field. Once I have all the structure for persons' offices I might try to make an automatic import,
#                                 # but I fear it is too messy to make it worthwhile.
#                                 comment = step2.text
#                                 if " von " in comment or " of " in comment or " de " in comment or "," in comment: # This field can contain either an additional epithet or the territory and title of a ruler. The former will be stored
#                                     # as part of the name, the latter will be relegated to the comment field.
#                                     # As a rough way of discerning both, anything with "von", "of" or "de" or a comma is regarded as belonging to a ruler
#                                     if comment not in pe.comments:
#                                         pe.comments = pe.comments + " / " + comment
#                                 else:
#                                     name_comment = " (" + comment + ")"
# #                                    name_variant = name_variant + name_number + " (" + comment + ")"
#                     name_variant = name_variant + name_number + name_comment
#                     for variant in pe.name_variant:
#                         if name_variant in variant:
#                             name_variant = ""
#                     if name_variant:
#                         pe.name_variant.append(name_variant)
"""
    datafields = find_datafields(record,"400")
    variants = []
    for datafield in datafields:
        name_variant = ""


        subfields = find_subfields(datafield,"a")
        if subfields:
            name_variant = subfields[0]
        subfields = find_subfields(datafield,"b")
        if subfields:
            name_variant = name_variant + " " + subfields[0]
        subfields = find_subfields(datafield,"c")
        if subfields:
            if " von " in subfields[0] or " of " in subfields[0] or " de " in subfields[0] or "," in subfields[0]:
                if subfields[0] not in comments:
                    comments = comments + " / " + subfields[0]
            else:
                name_variant = name_variant + " (" + subfields[0] + ")"
        if name_variant not in variants:
            variants.append(name_variant)
    return (variants, comments)





@classes.func_logger
def gnd_record_get_connected_persons(record):
    """
#                 case "500":
#                     conn_pe = classes.Person()
# #                    conn_pe.external_id = []
#                     for step2 in step1:
#                         match step2.get('code'):
#                             case "0":
#                                 if step2.text[0:8] == "(DE-588)":
#                                     conn_id = classes.ExternalReference()
#                                     conn_id.name = "GND"
#                                     conn_id.external_id = step2.text[8:]
#                                     conn_id.uri =  r'https://d-nb.info/gnd/' + conn_id.external_id
#                                     conn_pe.external_id.append(conn_id)

#                             case "a":
#                                 conn_pe.name = step2.text
#                             case "b":
#                                 conn_pe.name = conn_pe.name + " " + step2.text
#                             case "c":
#                                 conn_pe.name = conn_pe.name + "(" + step2.text + ")" #in this case I add this to the name
#                             # since it may make clear who the person is.
#                             case "4":
#                                 if step2.text[0:4] != "http": # in this subfield are both the relation codes and a URI for the relation codes, I don't need the latter
#                                     conn_pe.connection_type = step2.text
#                             case "9":
#                                 if step2.text[0:2] == "v:":
#                                     conn_pe.connection_comment = step2.text[2:]
#                                 if step2.text[0:2] == "Z:":
#                                     conn_pe.connection_time = step2.text[2:]
#                     if "VD-16 Mitverf." not in conn_pe.connection_comment:
#                             # someone connected all persons who appear together as authors in the VD16,
#                             # I want them removed.
#                         pe.connected_persons.append(conn_pe)
"""
    # Question: do we need here both 'name' and 'name_preferred'?
    # My idea was the following: I save very simple references to related persons
    # (connection type + name + id). If there was a record with this id in the database,
    # I replace the name with the preferred name in the record (they should be identical, but
    # maybe they are not).
    # If now there are full new entity records created (although probably as 'stubs'),
    # one should probably use here the field 'name_preferred' (and if the stub is upgraded,
    # it should probably be replaced with the name_preferred of the actual record for this person).
    # Does the field 'name' have a role at all? Probably not - but I still left it.
    # Perhaps, the name_preferred should also go as Preview into the ConnectedEntities, if one
    # does previews there.

    # How should this be connected to the person record? As long as there is no connection, it is not called,
    # and I cannot test it.
    connections = []
    datafields = find_datafields(record,"500")
    for datafield in datafields:
        p=classes.Node()
        p.type="Person"
        ec=classes.Edge()
        subfields = find_subfields(datafield,"0")
        if subfields:
            for subfield in subfields:
                external_reference = classes.ExternalReference()
                external_reference.name = "GND"
                if subfield[0:8] == "(DE-588)" or subfield[0:8] == "(DE-101)":
                    external_reference.external_id = subfield[8:]
                else:
                    external_reference.external_id = subfield
                external_reference.uri = r'https://d-nb.info/gnd/' + external_reference.external_id
                p.external_id.append(external_reference)
        subfields = find_subfields(datafield,"a")
        if subfields:
            p.name = subfields[0]
        subfields = find_subfields(datafield,"b")
        if subfields:
            p.name = p.name + " " + subfields[0]
        subfields = find_subfields(datafield,"c")
        if subfields:
            p.name = p.name + " (" + subfields[0] + ")"
        p.name_preferred = p.name
        subfields = find_subfields(datafield,"4")
        if subfields:
            if "http" not in subfields[0]:
                ec.connection_type = subfields[0] # Once one can give connection_types for both directions,
                # here the correct connection types in both directions have to be created
                ec.relationB = subfields[0]
        subfields = find_subfields(datafield,"9")
        if subfields:
            for subfield in subfields:
                if subfield[0:2] == "v:":
                    ec.connection_comment = subfield[2:]
                elif subfield[0:2] == "Z:":
                    ec.connection_time = subfield[2:]

        ec.entityB = p
        if "VD-16 Mitverf." not in ec.connection_comment:
            connections.append(ec)
    print(connections)
    return connections


@classes.func_logger
def gnd_record_get_connected_orgs(record):
    """
#                 case "510":
#                     conn_org = classes.EntityConnection()
#                     conn_org.external_id = []
#                     for step2 in step1:
#                         match step2.get('code'):
#                             case "0":
#                                 if step2.text[0:8] == "(DE-588)":
#                                     conn_id = classes.ExternalReference()
#                                     conn_id.name = "GND"
#                                     conn_id.external_id = step2.text[8:]
#                                     conn_id.uri =  r'https://d-nb.info/gnd/' + conn_id.external_id
#                                     conn_org.external_id.append(conn_id)
#                             case "a":
#                                 conn_org.name = step2.text
#                             case "b": #for sub-units of organisations - no clue if this will ever happen in my circumstances
#                                 conn_org.name = conn_org.name + " (" + step2.text + ")"
#                             case "4":
#                                 if step2.text[0:4] != "http": # in this subfield are both the relation codes and a URI for the relation codes, I don't need the latter
#                                     conn_org.connection_type = step2.text
#                             case "9":
#                                 if step2.text[0:2] == "v:":
#                                     conn_org.connection_comment = step2.text[2:]
#                                 if step2.text[0:2] == "Z:":
#                                     conn_org.connection_time = step2.text[2:]
#                     pe.connected_organisations.append(conn_org)

    """
    connections = []
    datafields = find_datafields(record,"500")
    for datafield in datafields:
        org=classes.Node()
        org.type="Organisation"
        ec=classes.Edge()
        subfields = find_subfields(datafield,"0")
        if subfields:
            for subfield in subfields:
                external_reference = classes.ExternalReference()
                external_reference.name = "GND"
                if subfield[0:8] == "(DE-588)" or subfield[0:8] == "(DE-101)":
                    external_reference.external_id = subfield[8:]
                else:
                    external_reference.external_id = subfield
                external_reference.uri = r'https://d-nb.info/gnd/' + external_reference.external_id
                org.external_id.append(external_reference)
        subfields = find_subfields(datafield,"a")
        if subfields:
            org.name = subfields[0]
        subfields = find_subfields(datafield,"b")
        if subfields:
            org.name = org.name + " (" + subfields[0] + ")"
        org.name_preferred = org.name
        subfields = find_subfields(datafield,"4")
        if subfields:
            if "http" not in subfields[0]:
                ec.connection_type = subfields[0] # Once one can give connection_types for both directions,
                # here the correct connection types in both directions have to be created
                ec.relationB = subfields[0]
        subfields = find_subfields(datafield,"9")
        if subfields:
            for subfield in subfields:
                if subfield[0:2] == "v:":
                    ec.connection_comment = subfield[2:]
                elif subfield[0:2] == "Z:":
                    ec.connection_time = subfield[2:]

        ec.entityB = org
        connections.append(ec)
    print(connections)
    return connections


@classes.func_logger
def gnd_record_get_connected_places(record):
    """
    #                 case "551":
#                     conn_pl = classes.EntityConnection()
#                     conn_id = classes.ExternalReference()
#                     for step2 in step1:
#                         match step2.get('code'):
#                             case "0":
#                                 if step2.text[0:8] == "(DE-588)":
#                                     conn_id.name = "GND"
#                                     conn_id.external_id = step2.text[8:]
#                                     conn_pl.external_id.append(conn_id)
#                                     conn_id.uri =  r'https://d-nb.info/gnd/' + conn_id.external_id
#                             case "a":
#                                 conn_pl.name = step2.text
#                             case "g":
#                                 conn_pl.name = conn_pl.name + " (" + step2.text + ")"
#                             case "4":
#                                 if step2.text[0:4] != "http": # in this subfield are both the relation codes and a URI for the relation codes, I don't need the latter
#                                     conn_pl.connection_type = step2.text
#                             case "9":
#                                 if step2.text[0:2] == "v:":
#                                     conn_pl.connection_comment = step2.text[2:]
#                                 if step2.text[0:2] == "Z:":
#                                     conn_pl.connection_time = step2.text[2:]
#                     if conn_pl.connection_type == "ortg":
#                         ortg_preview = ", born in " + conn_pl.name
#                     if conn_pl.connection_type == "orts":
#                         orts_preview = ", died in " + conn_pl.name
#                     if conn_pl.connection_type == "ortw":
#                         ortw_preview = ", active in " + conn_pl.name
#                     pe.connected_locations.append(conn_pl)
"""
    connections = []
    datafields = find_datafields(record,"500")
    for datafield in datafields:
        pl=classes.Node()
        pl.type="Place"
        ec=classes.Edge()
        subfields = find_subfields(datafield,"0")
        if subfields:
            for subfield in subfields:
                external_reference = classes.ExternalReference()
                external_reference.name = "GND"
                if subfield[0:8] == "(DE-588)" or subfield[0:8] == "(DE-101)":
                    external_reference.external_id = subfield[8:]
                else:
                    external_reference.external_id = subfield
                external_reference.uri = r'https://d-nb.info/gnd/' + external_reference.external_id
                pl.external_id.append(external_reference)
        subfields = find_subfields(datafield,"a")
        if subfields:
            pl.name = subfields[0]
        subfields = find_subfields(datafield,"g")
        if subfields:
            pl.name = pl.name + " (" + subfields[0] + ")"
        pl.name_preferred = pl.name
        subfields = find_subfields(datafield,"4")
        if subfields:
            if "http" not in subfields[0]:
                ec.connection_type = subfields[0] # Once one can give connection_types for both directions,
                # here the correct connection types in both directions have to be created with the help of all the
                # long lists of different terms.
                ec.relationB = subfields[0]
        subfields = find_subfields(datafield,"9")
        if subfields:
            for subfield in subfields:
                if subfield[0:2] == "v:":
                    ec.connection_comment = subfield[2:]
                elif subfield[0:2] == "Z:":
                    ec.connection_time = subfield[2:]

        ec.entityB = pl
        connections.append(ec)
    print(connections)
    return connections




@classes.func_logger
def gnd_record_get_stuff(record):
    """
    I assume that this is all no longer needed.
#         #if pe.dates_from_source:
#             #pe.dates = dates_parsing(pe.dates_from_source)
#         if pe.comments:
#             comments_preview = " (" + pe.comments + ")"
#         if pe.name_variant:
#             name_variant_preview = ", also called: "
#             for variant in pe.name_variant:
#                 name_variant_preview = name_variant_preview + variant + "; "
#             name_variant_preview = name_variant_preview[:-2]


#         pe.preview = pe.name_preferred + date_preview + ortg_preview + ortw_preview + orts_preview + name_variant_preview + comments_preview
#         potential_persons_list.append(pe)
        #print(potential_persons_list)
#        print(pe.preview)


#        print(pe.external_id)
#        print(pe.name_preferred)
#        print(pe.name_variant)
#        print(pe.sex)
#        print(pe.comments)
#        print(pe.connected_persons)
#        print(pe.dates_from_source)
#        print(pe.connected_organisations)
#        print(pe.connected_locations)
#        pprint(pe)
#    print(persons_list)
#        print(person_found.model_dump())
        connected_person = classes.EntityConnection()
        connected_person.connection_type = "Candidate"
        connected_person.person = person_found
#        print(connected_person.model_dump())
#        print(result.model_dump())
        result.append(connected_person)
#        print(result.model_dump())







    #record = root[2][0][2][0][0]
    #print(record.text)
    #print("potential persons list made")
"""
# This section contains four elements: connected organisations, connected places, dates, and professions.
# The first two should function analogous to connected persons above, but it does not make sense
# to refactor them as long as I cannot test gnd_record_get_connected_persons.   The other two have been copied
# into separate functions

    result = ""
    return result


@classes.func_logger
def get_gnd_comments(record, comments):
    """
    #                 case "678":
#                     for step2 in step1:
#                         match step2.get('code'):
#                             case "b":
#                                 if pe.comments:
#                                     pe.comments = step2.text + "; " + pe.comments
#                                 else:
#                                     pe.comments = step2.text
    """
    datafields = find_datafields(record,"678")
    for datafield in datafields:
        subfields = find_subfields(datafield,"b")
        if subfields:
            comments = comments + "; " + subfields[0]
    if comments[0:2] == "; ":
        comments = comments[2:]
    return comments

@classes.func_logger
def get_gnd_dates(record):
    """
                case "548":
#                     date = classes.DateImport()
#                     for step2 in step1:
#                         match step2.get('code'):
#                             case "a":
#                                 date.datestring_raw = step2.text
#                             case "v":
#                                 date.date_comments = step2.text
#                             case "4":
#                                 if step2.text[0:4] != "http": # in this subfield are both the relation codes and a URI for the relation codes, I don't need the latter
#                                     date.datetype = step2.text
#                     if date.datetype == "datl":
#                         date_preview = " (" + date.datestring_raw + ")"
#                     if date.datetype == "datw" and date_preview == "": # only shown in the preview if there is no datl
#                         date_preview = " (active: " + date.datestring_raw + ")"
#                     pe.dates_from_source.append(date)
#                     print("Date as imported from GND: ")
#                     print(pe.dates_from_source)
#  #                   pe.dates_from_source.append(date)
#                     # If the GND contains the exact date ("datx"), it also gives the years only ("datl").
#                     # The latter should be removed later

"""
    datafields = find_datafields(record,"548")
    dates_from_source = []
    date = classes.DateImport()
    for datafield in datafields:
        subfields = find_subfields(datafield,"a")
        if subfields:
            date.datestring_raw = subfields[0]
        subfields = find_subfields(datafield,"v")
        if subfields:
            date.date_comments = subfields[0]
        subfields = find_subfields(datafield,"4")
        for subfield in subfields:
            if subfield[0:4] != "http":
                date.datetype = subfield
                break
        dates_from_source.append(date)
        # in the original version, I had also a date_preview field that had to be filled.
        # One should either introduce such a field, or parse the dates straight away -
        # the latter would make most sense.
        # Since this function is not only used for persons but also for organisations, a potential
        # preview must not only cater for "datl" (no comments needed) and "datw" ("active "),
        # but also for "datb" ("extant ")
        return (dates_from_source)


@classes.func_logger
def parse_gnd_profession(record, comments):

    #                 case "550": #This is used for professions or for general headings. This information is simply displayed in the "comment" field
#                     # so that it can be used to manually create the links I will need.
#                     for step2 in step1:
#                         match step2.get('code'):
#                             case "a":
#                                 if pe.comments:
#                                     pe.comments = step2.text + "; " + pe.comments
#                                 else:
#                                     pe.comments = step2.text
#
    datafields = find_datafields(record,"550")
    profession = ""
    for datafield in datafields:
        subfields = find_subfields(datafield,"a")
        if subfields:
            for subfield in subfields:
                profession = profession + "; " + subfield
    if profession[0:2] == "; ":
        profession = profession[2:]
    if comments == "":
        comments = profession
    else:
        comments = comments + "; " + profession
    return comments


@classes.async_func_logger
async def find_and_parse_organisation_gnd(authority_url):
    """
This is largely a copy after the find_and_parse_person_gnd function.
It is still untested. ONly few functions had to be written anew, most
were reused from parsing person records.
    """
    result = []
    content=await get_external_data.get_web_data(authority_url)
    root = etree.XML(content)
    records=root.find("records", namespaces=root.nsmap)
    for record in records:
        exclude = gnd_org_record_exclusion(record)
        if not exclude:
            print("found record")

            org_found=classes.Node()
            org_found.external_id.extend(gnd_record_get_gnd_internal_id(record))
            org_found.external_id.extend(gnd_record_get_external_references(record))
            org_found.name_preferred = gnd_org_record_get_name_preferred(record)
            org_found.name_variant = gnd_org_record_get_name_variant(record)
    #        org_found.gnd_id=gnd_record_get_gnd_id(record)
            org_found.type="Organisation"
    #        org_found.connected_persons =  gnd_record_get_connected_persons(record)
    #        org_found.connected_organisations = gnd_record_get_connected_orgs(record)
#           org_found.connected_places = gnd_record_get_connected_places(record)

            org_found.dates_from_source = get_gnd_dates(record)
            org_found.comments = parse_gnd_profession(record, org_found.comments)
            org_found.comments = get_gnd_comments(record, org_found.comments)
    #        print(org_found)

            connected_org = classes.Edge()
            connected_org.connection_type = "Candidate"
            connected_org.entityA = org_found
            result.append(connected_org)
    return result

@classes.func_logger
def gnd_org_record_exclusion(record):
    """
    This module checks two fields in the GND record - if one of them has a relevant entry, the entire
    record is excluded from the list of candidates.
                    case "075": # This entity type  is only important for removing records with entity type 'wis' from the search results - these are records for individual
                            # manuscripts, but have the same record type as organisations.
                    for step2 in step1:
                        match step2.get('code'):
                            case "b":
                                entity = step2.text

                case "260":
                    cross_reference = True # Records with entries in this field should not be used

    """
    exclude = False
    datafields = find_datafields(record,"075")
    for datafield in datafields:
        subfields = find_subfields(datafield,"b")
        for subfield in subfields:
            if subfield == "wis":
                exclude = True

    datafields = find_datafields(record, "260")
    if datafields:
        exclude = True
    return exclude


@classes.async_func_logger
def gnd_org_record_get_name_preferred(record):
    """
    Takes the preferred name of an organisation
                case "110":
                    for step2 in step1:
                        match step2.get('code'):
                            case "a":
                                org.name_preferred = step2.text
                            case "b": # probably used for subdivisions - I don't think this will happen often
                                org.name_preferred = org.name_preferred + " (" + step2.text + ")"
                            case "g": # used for the location of subdivisions - just in case it is necessary in some cases to avoid confusion
                                org.name_preferred = org.name_preferred + " (" + step2.text + ")"
                            case "x": # also sued for some subdivisions
                                org.name_preferred = org.name_preferred + " (" + step2.text + ")"

    """
    name_preferred = ""
    datafields = find_datafields(record,"110")
    for datafield in datafields:
        subfields = find_subfields(datafield,"a")
        if subfields:
            name_preferred = subfields[0]
        subfields = find_subfields(datafield,"b")
        if subfields:
            name_preferred = name_preferred+ " (" + subfields[0] + ")"
        subfields = find_subfields(datafield,"g")
        if subfields:
            name_preferred = name_preferred+ " (" + subfields[0] + ")"
        subfields = find_subfields(datafield,"x")
        if subfields:
            name_preferred = name_preferred+ " (" + subfields[0] + ")"
    return (name_preferred)


@classes.func_logger
def gnd_org_record_get_name_variant(record):
    """
                    case "410":
                    name_subdivision = ""
                    for step2 in step1:
                        match step2.get('code'):
                            case "a":
                                name_variant = step2.text
                            case "b": # The numbering for rulers
                                name_subdivision =  " (" + step2.text + ")"
                    name_variant = name_variant + name_subdivision
                    for variant in org.name_variant:
                        if name_variant in variant:
                            name_variant = ""
                    if name_variant:
                        org.name_variant.append(name_variant)

                        """
    datafields = find_datafields(record,"410")
    variants = []
    for datafield in datafields:
        name_variant = ""
        subfields = find_subfields(datafield,"a")
        if subfields:
            name_variant = subfields[0]
        subfields = find_subfields(datafield,"b")
        if subfields:
            name_variant = name_variant + " (" + subfields[0] + ")"
        if name_variant not in variants:
            variants.append(name_variant)
    return (variants)



@classes.func_logger
def gnd_parsing_place_part_of_list(root):
    """
Unfortunately, the search for places often yields several hundred results. Since the normal search function only downloads 100 results
per bathc, I may need to run it several times, and hence I have to call the search several times.
In order to do so, I had to divide the function gnd_parsing_place. The function with this name now only launches one or more search options to bring back all results
and later filters out many irrelevant results that I annoyingly cannot exclude from the search.
The longest part of the function the actual parsing of the XMl results, is moved to this function gnd_parsing_place_part_of_list.
    """

    records=root.find("records", namespaces=root.nsmap)

    result = []
    for record in records:
#        print("arrived in parsing record")

        pl_found = classes.Node()
        entity_types = gnd_place_record_get_entity_type(record)
        if(("gik" in entity_types or "giz" in entity_types or "gxz" in entity_types) and "gil" not in entity_types):
            # This is for searching for towns. If I want to use this function later also for searching e.g., countries,
            # I have to create here different filters
            pl_found.external_id.extend(gnd_record_get_gnd_internal_id(record))
            pl_found.external_id.extend(gnd_record_get_external_references(record))
            pl_found.external_id.extend(gnd_place_record_get_geonames(record))
            #pl_found.coordinates = gnd_place_record_get_coordinates(record)
            # up to now, entity does not allow for coordinates, this has to change
            pl_found.name_preferred = gnd_place_record_get_name_preferred(record)
            pl_found.name_variant = gnd_place_record_get_name_variant(record)
    #        org_found.gnd_id=gnd_record_get_gnd_id(record)
            pl_found.type="Place"
    #        pl_found.connected_persons =  gnd_record_get_connected_persons(record)
    #        pl_found.connected_organisations = gnd_record_get_connected_orgs(record)
#           pl_found.connected_places = gnd_record_get_connected_places(record)

            pl_found.dates_from_source = get_gnd_dates(record) # just in case
            pl_found.comments = parse_gnd_profession(record, pl_found.comments)
            pl_found.comments = get_gnd_comments(record, pl_found.comments)
    #        print(org_found)

            connected_place = classes.Edge()
            connected_place.connection_type = "Candidate"
            connected_place.entityA = pl_found
            result.append(connected_place)

#            print(potential_places_list)
    return result

def gnd_place_record_get_entity_type(record):
    """
    The entity indicates if the place is a town or a building or a country etc.
    It thus determines, if a place should be parsed and entered into the list
    for selection.
                    case "075":
                    for step2 in step1:
                        match step2.get('code'):
                            case "b":
                                entity_list.append(step2.text)
    """
    entities = []
    datafields = find_datafields(record,"075")
    for datafield in datafields:
        subfields = find_subfields(datafield,"b")
        if subfields:
            entities.append.subfields[0]
    return entities

def gnd_place_record_get_geonames(record):
    """
    The geonames id is stored in a separate field.
               case "024":
                    pl_id = classes.ExternalReference()
                    for step2 in step1:
                        match step2.get('code'):
                            case "a":
                                pl_id.external_id = step2.text
                            case "2":
                                pl_id.name = step2.text
                        if pl_id.name == "geonames":
                            pl_id.uri = "https://sws.geonames.org/" + pl_id.external_id
                            pl.external_id.append(pl_id)
"""
    external_references=[]
    datafields = find_datafields(record,"024")
    for datafield in datafields:
        external_reference = classes.ExternalReference()
        subfields = find_subfields(datafield,"a")
        if subfields:
            external_reference.external_id = subfields[0]
        subfields = find_subfields(datafield,"2")
        if subfields:
            external_reference.name = subfields[0]
            if external_reference.name == "geonames":
                external_reference.uri = "https://sws.geonames.org/" + external_references.external_id
                external_references.append(external_reference)
    return(external_references)

def gnd_place_record_get_coordinates(record):
    """
                case "034":
                    coordinates = classes.Coordinates()
                    pl_id = classes.ExternalReference()
                    for step2 in step1:
                        match step2.get('code'):
                            case "d":
                                coordinates.west = step2.text
                            case "e":
                                coordinates.east = step2.text
                            case "f":
                                coordinates.north = step2.text
                            case "g":
                                coordinates.south = step2.text
                    pl.coordinates.append(coordinates)

    """
    coordinates_list=[]
    datafields = find_datafields(record,"034")
    for datafield in datafields:
        coordinates = classes.Coordinates()
        subfields = find_subfields(datafield,"d")
        if subfields:
            coordinates.west = subfields[0]
        subfields = find_subfields(datafield,"e")
        if subfields:
            coordinates.east = subfields[0]
        subfields = find_subfields(datafield,"f")
        if subfields:
            coordinates.north = subfields[0]
        subfields = find_subfields(datafield,"g")
        if subfields:
            coordinates.south = subfields[0]
        coordinates_list.append(coordinates)
    return coordinates_list

def gnd_place_record_get_name_preferred(record):
    """
                    case "151":
                    for step2 in step1:
                        match step2.get('code'):
                            case "a":
                                pl.name_preferred = step2.text
                            case "x" | "z": # some kind of subdivision, I don't know how often it will appear
                                pl.name_preferred = pl.name_preferred + " (" + step2.text + ") "

    """
    name_preferred = []
    datafields = find_datafields(record,"151")
    for datafield in datafields:
        subfields = find_subfields(datafield,"a")
        if subfields:
            name_preferred = subfields[0]
        # "x" and "z" in subfields are for subdivisions of some kind
        # I have no clue if they ever occur in images relevant to me.
        subfields = find_subfields(datafield,"x")
        if subfields:
            name_preferred = name_preferred + " (" + subfields[0] + ")"
        subfields = find_subfields(datafield,"z")
        if subfields:
            name_preferred = name_preferred + " (" + subfields[0] + ")"
    return name_preferred

def gnd_place_record_get_name_variant(record):
    """

                        case "451":
                    for step2 in step1:
                        match step2.get('code'):
                            case "a":
                                name_variant = step2.text
                            case "i" | "x" | "z": # different comment fields
                                name_number =  " (" + step2.text + ") "
                    for variant in pl.name_variant:
                        if name_variant in variant:
                            name_variant = ""
                    if name_variant:
                        name_variant = name_variant + name_number
                        #just in case this name_number is ever used with places
                        pl.name_variant.append(name_variant)

    """
    variants = []
    datafields = find_datafields(record,"451")
    for datafield in datafields:
        name_variant = ""
        subfields = find_subfields(datafield,"a")
        if subfields:
            name_variant = subfields[0]
        # I don't know if the subfields i, x and z ever contain any relevant information,
        # so I add them just in case.
        subfields = find_subfields(datafield,"i")
        if subfields:
            name_variant = name_variant + " )" + subfields[0] + ")"
        subfields = find_subfields(datafield,"x")
        if subfields:
            name_variant = name_variant + " (" + subfields[0] + ")"
        subfields = find_subfields(datafield,"z")
        if subfields:
            name_variant = name_variant + " (" + subfields[0] + ")"
        if name_variant not in variants:
            variants.append(name_variant)
    return (variants)



async def parse_place_gnd(authority_url):
    """
\todo

    """

    potential_places_list = []
    potential_places_list_complete = []
    search_term = authority_url[89:-61]
    if "%" in search_term: # If there was a word search, I only search for the first word
        search_term = search_term.split("%")[0]
    content=await get_external_data.get_web_data(authority_url)
    root = etree.XML(content)
    if root[1].text:
        record_count = int(root[1].text)
    else:
        record_count = 0
    print('Number of records found')
    print(record_count)

    if record_count > 0:
        potential_places_list = gnd_parsing_place_part_of_list(root)

    if record_count > 100:
        record_count = record_count-100
        start_record = 101
        authority_url_basis = authority_url + "&startRecord="

#         authority_url_basis = authority_url[:-18] + "startRecord="
        while record_count > 0:
            authority_url = authority_url_basis + str(start_record)
            content=await get_external_data.get_web_data(authority_url)
            root = etree.XML(content)
            additional_potential_places_list = gnd_parsing_place_part_of_list(root)
            potential_places_list = potential_places_list + additional_potential_places_list
            record_count = record_count - 100
            start_record = start_record + 100
    if potential_places_list:
#        print("List of potential places: ")
#        print(potential_places_list)
        for place in potential_places_list:
            if search_term in place.name_preferred or len(potential_places_list) == 1:
#                print(place.name_preferred)
                potential_places_list_complete.append(place)
    return potential_places_list_complete


#person = Person()
#person.id_name = "GND"
#person.id = "11900108X" #Lautensack
#person.role = "prt"
#person.id = "118650130" # Aristotle
#person.id = "118780743" #Louis XVIII
#person.name = "Lautensack, Paul"
#person.name = "Rubens, Peter Paul"
#person.name = "Andreas Asula"
#record = person_identification(person)
#organisation = Organisation()
#organisation.id_name = "GND"
#organisation.id = "2133444-4"
#record = organisation_identification(organisation)
#authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + organisation.id + r'%20and%20BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100'
#print(authority_url)
#record = gnd_parsing_organisation(authority_url)
#print(record)
#organisation.name = "Bamberg, Staatsbibliothek"
#authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=Koe%3DBamberg,%20Staatsbibliothek%20%20and%20BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100'
#record = gnd_parsing_organisation(authority_url)
#record = organisation_identification(organisation)
#print(record)
#authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D4086808-4%20and%20BBG%3DTg*&recordSchema=MARC21-xml&maximumRecords=100'
#place = Place()
#place.id_name = "GND"
#place.id = "4086808-4"
#place.name = "Frankfurt, Main"
#x = place_identification(place)

#print(x)


@classes.func_logger
async def identify_making_process(making_processes):
    """
    This module has bene primarily made for parsing information about the making process of a manuscript or printed book
    that had been entered manually during the ingest process.
    If such information is added when working on individual records, it might be possible to adopt this module, but one would probably rather go directly
    to parsing the individual parts of it.
    Manuscripts have by default one Making Process, Printed Books two (in theory three, but the third, printing, is already defined by bibliographic data
    and hence would not be added here).
    Each making process has a number (currently as integer, although I wonder if one should not rather use a string to allow for e.g. 1a, 1b etc),
    a process_type (the activity, e.g. design, blockcutting, etc.), and a process qualifier (e.g., none, attributed, follower of, etc.) - these two
    will eventually probably belong drop-down fields.
    It also has three fields that need parsing - one for a person (normally the artist), one for a place, and one for a date.
    The person will be parsed similar to persons conntected to a book - but instead of the GND, the Getty ULAN would be the preferred source of information.
    The place will be parsed as places conntected to a book (also here historical names), and the GND will also here be the principal source.
    The date will be entered according to relatively simple rules that the editors would have to learn and would be parsed in a separate routine.

    Eventually, two more fields will be added - the Medium, and the Illustrated Text.
    """
    for making_process in making_processes:
        place = making_process.place
        if place.name != "":
            place.role = "Place of Making"
            place_new = await identify_place(place)
            print(place_new)
            making_process.place = place_new
        artist = making_process.person
        if artist.name != "":
            print("Artist found")
            print(artist.name)
            artist.role = "art"
            artist_new = await identify_person(artist)
            print(artist_new)
            making_process.person = artist_new
        date = making_process.date
        if date.datestring_raw != "":
            print("Date_found")
            print(date.datestring_raw)
            try:
                date_new = parse_date.parse_manually_entered_date(date.datestring_raw)
                making_process.date = date_new
            except classes.InvalidDateStringException as d:
                print(f"String could not be divided into individual dates: {d}")
            except classes.InvalidDateException as e:
                print(f"Failed to parse date string {e}")
            except classes.InvalidMonthException as f:
                print(f"Failed to parse date string {f}")
            except classes.InvalidDayException as g:
                print(f"Failed to parse date string {g}")
            except classes.InvalidDateRangeException as h:
                print(f"{h}")


    return making_processes

#class MarcxmlSubfield():
#    string : key
#    string : value


# @classes.func_logger
# def find_datafields(record,tag_id):
#     """
#     This function returns for a datafield in an MARCXML record a
#     hash with the subfields, where the key is the code attribute
#     and the value is the text in the subfield.
#     Note that there is only one subfield with the same key allowed
#     """
# #    results=np.array([])
#     print(tag_id)
#     datafields=record.findall("{*}recordData/{*}record/{*}datafield[@tag='"+tag_id+"']")
# #    print(datafields)
#     for datafield in datafields:
#         subfields=datafield.findall("{*}subfield")
# #        subfield_hash={}
#         result=[]
#         for subfield in subfields:
#             key= subfield.get("code")
#             value=subfield.text

# #            subfield_hash[key].append(value)
#             s = [key,value]
#             print(s)
# #            print("Hash"+key+value)
#             result.append(s)
#         results = np.append(results,[result],0)
#     print("resulting datafields")
#     print(results)
#     return results

# @classes.func_logger
# def find_tuple(l,key):
#     r=[]
#     for e in l:
#         if e[0] == key:
#             print(e[0],e[1],key)
#             r.append(e[1])
#             print(r)
#     return r

def find_datafields(record,tag_id):
    datafields=record.findall("{*}recordData/{*}record/{*}datafield[@tag='"+tag_id+"']")
    return datafields

def find_subfields(datafield,subfield_id):
    r=[]
    subfields=datafield.findall("{*}subfield")
    for subfield in subfields:
        key= subfield.get("code") (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[106:205]
==bpf_be_fastapi.parse_istc_old:[132:230]
                    pl_duplicate.name = bi.places[0].name
                    pl_duplicate.role = "pup"
                    bi.places.append(pl_duplicate)
                    # I append the place again, this time as place of publication
                    # I could instead replace the string for the role with a list,
                    # but this is a lot more work, so I have to think
                    # if this is appropriate (I fear it is)
                else:
                    printer_name_long = imprint_name_long


                if printer_name_long:
#                    print("printer_name_long: " + printer_name_long)
                    printer_name_long = printer_name_long.replace("[", "")
                    printer_name_long = printer_name_long.replace("]", "")

                    if " and " in printer_name_long: #in this case, there are two printers
                        printer_name_long_divided = printer_name_long.split(" and ")
                        printer_counter = 0
                        while printer_counter < len(printer_name_long_divided):
                            person_name=""
                            printer_name = printer_name_long_divided[printer_counter]
                            printer_name = printer_name.strip(" [],")
                            if " " in printer_name:
                                #if there is a blank inside the name -
                                # hence it is more than just a Christian name
                                    person_name = printer_name
                            else: # If there is only a Christian name

                                if printer_name_long_divided[printer_counter+1]:
                                    next_printer = printer_name_long_divided\
                                        [printer_counter+1].strip()
                                    # if there is a next printer in the list
                                    # whose name has at least two words
                                    if " " in next_printer:
                                        next_printer_divided = next_printer.split(" ")
                                        next_printer_surname = next_printer_divided[-1]
                                        person_name = printer_name + " " + next_printer_surname
                                else: # if there is no next printer,
                                    #or the next printer does not have a surname, either
                                    person_name = printer_name
                            pe=classes.make_new_role(role="prt",person_name=person_name)
                            print("pe in parse_istc")
                            print(pe)
                            bi.persons.append(pe)
                            printer_counter = printer_counter + 1
                    else: #If there is only one printer
                        pe=classes.make_new_role(role="prt",person_name=printer_name_long)
                        print(pe)
                        bi.persons.append(pe)

                if publisher_name_long:
                    print("publisher_name_long: " + publisher_name_long)
                    if " and " in publisher_name_long: #in this case, there are two publishers
                        publisher_name_long_divided = publisher_name_long.split(" and ")
                        print("Two publishers")
                        publisher_counter = 0
                        while publisher_counter < len(publisher_name_long_divided):
                            publisher_name = publisher_name_long_divided[publisher_counter]
                            publisher_name = publisher_name.strip(" []")
                            if " " in publisher_name:
                                #if there is a blank inside the name -
                                # hence it is more than just a Christian name
                                pepersonname = publisher_name
                            elif "himself" in publisher_name:
                                pepersonname = printer_name_long
                                # in this case there can only be one printer
                            else: # If there is only a Christian name
                                if publisher_name_long_divided[publisher_counter+1]:
                                    next_publisher = publisher_name_long_divided\
                                        [publisher_counter+1].strip()
                                    # if there is a next publisher in the list
                                    # whose name has at least two words
                                    if " " in next_publisher:
                                        next_publisher_divided = next_publisher.split(" ")
                                        next_publisher_surname = next_publisher_divided[-1]
                                        pepersonname = publisher_name + " " + next_publisher_surname
                                    else: # if the next printer doesn't have a surname, either
                                        pepersonname = publisher_name
                                else: # if there is no next printer
                                    pepersonname = publisher_name
                            print("Publisher name: "+ pe.name)
#                            pe = classes.SelectionCandidate()
#                            pe.person = classes.Person()
#                            pe.person.role = "pbl"
                            publisher=classes.make_new_role(role="pbl",person_name=pepersonname)
                            bi.persons.append(publisher)
                            publisher_counter = publisher_counter + 1
                    else: #If there is only one publisher
#                        pe = classes.SelectionCandidate()
#  #                       pe.person = classes.Person()
#                         pe.person.name = publisher_name_long
#                         pe.person.role = "pbl"
                        publisher=classes.make_new_role(role="pbl",person_name=publisher_name_long)
                        bi.persons.append(publisher)
        if "title" in istc_record_short:
            bi.title = istc_record_short["title"]
 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[710:823]
==bpf_be_fastapi.parse_gnd:[717:821]
    return external_references

    # x = find_datafields(record,"001")
    # print(x)
    # for y in x:
    #     if y.get("a") is not None:
    #         external_reference = classes.ExternalReference()
    #         external_reference.name = "GND_intern"
    # datafields=record.findall("{*}recordData/{*}record/{*}datafield[@tag='"+tag_id+"']")
    # for datafield in datafields:
    #     subfields=datafield.findall("{*}subfield")
    #     subfield_hash={}
    #     for subfield in subfields:
    #         key= subfield.get("code")
    #         value=subfield.text


@classes.func_logger
def gnd_record_get_gnd_id(record):
    gnd_id=""
    datafields = find_datafields(record,"035")
    for datafield in datafields:
        subfields = find_subfields(datafield,"a")
        print(subfields)
        if subfields:
            if subfields[0][0:8] == "(DE-588)":
                gnd_id=subfields[0][8:] #The latter cuts out the prefix '(DE-588)'.
    print(gnd_id)
    return gnd_id

@classes.func_logger
def gnd_record_get_external_references(record):
    """
#                 case "035":
#                     for step2 in step1:
#                         match step2.get('code'):
#                             case "a":
#                                 pe_id = classes.ExternalReference()
#                                 pe_id.name = "GND"
#                                 if step2.text[0:8] == "(DE-588)":
#                                     pe_id.external_id = step2.text[8:] #The latter cuts out the prefix '(DE-588)'.
#                                     pe_id.uri = r'https://d-nb.info/gnd/' + pe_id.external_id
#                                     duplicate_id = False  # Sometimes, the record containing the GND ID appears twice, hence it should not be added a second time.
#                                     for id_duplicate in pe.external_id:
#                                         if id_duplicate.uri == pe_id.uri:
#                                             duplicate_id = True
#                                     if not duplicate_id:
#                                         pe.external_id.append(pe_id)
# #                                    if not pe.external_id: #
# #                                        pe.external_id.append(pe_id)
#                                 # Quite often, there are several GND records for one person, and if discovered, they are merged, and all GND IDs but become obsolete.
#                                 # However, they are still stored in the record (035z) and are found by the search.
#                                 # Hence, this ID may be different from the person.id I used for the search in the first place.
"""
    external_references=[]
    datafields = find_datafields(record,"035")
    for datafield in datafields:
        subfields = find_subfields(datafield,"a")
        if subfields:
            external_reference = classes.ExternalReference()
            external_reference.name="GND"
            if subfields[0][0:8] == "(DE-588)" or subfields[0][0:8] == "(DE-101)":
                # sometimes, there is this prefix, which is unnecessary and should be cut out.
                external_reference.external_id=subfields[0][8:]
            else:
                external_reference.external_id=subfields[0][0:]
            external_reference.uri = r'https://d-nb.info/gnd/' + external_reference.external_id
            for extant_external_reference in external_references:
                if extant_external_reference.name == external_reference.name and \
                    extant_external_reference.external_id == external_reference.external_id:
                    break
            else:
                external_references.append(external_reference)

#   Annoyingly, the search also finds IDs from the old database PND. If it is possible that a PND ID is the same as the GND ID of a
#   different record, I have to include a function to delete this record from the results (I am enquiring if this is the case)

    return external_references



@classes.func_logger
def gnd_record_get_name_preferred(record):
    """
    Takes the preferred name from field 100
    Possible additions: some more standard identifyers in 100c
    e.g. "Gott", "Biblische Person" could be moved to 'Comment'
    Or: standardised terms in the 'Comment' section may even
    be used for putting Person records into the right group
    of person
    """
# Set preferred name
    name_preferred = ""
    comments = ""
    datafields = find_datafields(record,"100")
    for datafield in datafields:
        subfields = find_subfields(datafield,"a")
        if subfields:
            name_preferred = subfields[0]
        subfields = find_subfields(datafield,"b")
        if subfields:
            name_preferred = name_preferred+ " " + subfields[0]
        subfields = find_subfields(datafield,"c")
        if subfields: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[393:430]
==bpf_be_fastapi.parse_istc_old:[352:389]
    match date_prefix:
        case "About "|"about ":
            string_prefix = "about "
            string_year = date_year + " "
            start_year = int(date_year) - 1
            end_year = int(date_year) + 1
        case "Before " | "before ":
            string_prefix = "before "
            string_year = date_year + " "
            start_year = int(date_year) - 2
            end_year = int(date_year)
        case "Shortly before " | "shortly before ":
            string_prefix = "shortly before "
            # I am not sure if I will suppress this eventually??
            string_year = date_year + " "
            start_year = int(date_year) - 1
            end_year = int(date_year)
        case "Not before " | "not before ":
            string_prefix = "not before "
            string_year = date_year + " "
            start_year = int(date_year)
            end_year = int(date_year) + 2
        case "After " | "after ":
            string_prefix = "after "
            string_year = date_year + " "
            start_year = int(date_year)
            end_year = int(date_year) + 2
        case "Shortly after " | "shortly after ":
            string_prefix = "shortly after "
            string_year = date_year + " "
            start_year = int(date_year)
            end_year = int(date_year) + 1
        case "Not after " | "not after ":
            string_prefix = "not after "
            string_year = date_year + " "
            start_year = int(date_year) - 2
            end_year = int(date_year) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_person:[439:475]
==bpf_be_fastapi.ingest_place:[387:423]
            if re.match(
                connected_location_comment_is_date,
                connected_location.connection_comment,
            ):  # This means that the 'comment' field contains information that should have gone into the 'time' field.
                if connected_location.connection_time:
                    connected_location.connection_time = (
                        connected_location.connection_time
                        + ", "
                        + connected_location.connection_comment
                    )
                else:
                    connected_location.connection_time = (
                        connected_location.connection_comment
                    )
                connected_location.connection_comment = ""
            elif connected_location.connection_comment[0:12] == "Wirkungsort ":
                connected_location.connection_time = (
                    connected_location.connection_comment[12:]
                )
                connected_location.connection_comment = "wirkungsort"
            elif connected_location.connection_comment[0:8] == "Wohnort ":
                connected_location.connection_time = (
                    connected_location.connection_comment[8:]
                )
                connected_location.connection_comment = "wohnort"

            new_connected_location = classes.Edge()
            new_connected_location.id = connected_location.id
            new_connected_location.external_id = connected_location.external_id
            new_connected_location.name = connected_location.name
            new_connected_location.connection_type = connected_location.connection_type
            new_connected_location.connection_time = connected_location.connection_time
            new_connected_location.connection_comment = (
                connected_location.connection_comment
            )
            # For connection time see above under new connected person (only relevant for location of activity) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[338:373]
==bpf_be_fastapi.parse_gnd_old:[264:299]
            candidate.internal_id = candidate_result["id"]
            candidate.name_preferred = candidate_result["name_preferred"]
            candidate.internal_id_org_type1 = candidate_result["org_type1"]
            candidate.preview = candidate.name_preferred + " (in Database)" # Maybe I add other information to it later.
            print("orgtype1 in search for name_variant: ")
            print(candidate.internal_id_org_type1)
            candidate_duplicate = False # This is needed to avoid having a candidate listed twice, it is rather longwided since I cannot use a simple if ... in thing in class instances.
            for extant_candidate in organisation.potential_candidates:
                if extant_candidate.name_preferred == candidate.name_preferred:
                    candidate_duplicate = True
            if not candidate_duplicate:

#            if candidate not in organisation.potential_candidates:
#                print("Candidate not yet in list")
                organisation.potential_candidates.append(candidate)
            # The following is about a warning if the found organisations have the wrong type. I could not try it out, since the VD17 always gives IDs of organisations,
            # and the ISTC does not have them.
            for candidate in organisation.potential_candidates:
                print("Repository types present:")
                print(candidate.internal_id_org_type1)
                print("Repository types needed: ")
                print(organisation.internal_id_org_type1_needed)
                if organisation.internal_id_org_type1_needed not in candidate.internal_id_org_type1:
                    org_type1_present = ""
                    for t in candidate.internal_id_org_type1:
                        org_type1_present = org_type1_present + "' and '" + t + "'"
                    org_type1_present = org_type1_present[5:]
                    candidate.internal_id_org_type1_comment = "This organisation is currently catalogued as "\
                          + org_type1_present + ", but not as '" + organisation.internal_id_org_type1_needed + "'. The latter will be added if this record has been saved. "

        if not organisation.potential_candidates: #if nothing has been found in the database
            organisation_name_search = organisation.name
            for old, new in parsing_helpers.url_replacement.items():
                organisation_name_search = organisation_name_search.replace(old, new)
            authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=Koe%3D' + organisation_name_search + r'%20and%20BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100' (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[552:587]
==bpf_be_fastapi.parse_istc_old:[456:491]
    if date_between_day != "":
        string_day_between = date_between_day
        end_day = int(string_day_between)
    elif date_between_year != "":
        # Thus, there is no end day but an end year in this case,
        # the end month has to be December.
        if end_month in [1, 3, 5, 7, 8, 10, 12]:
            end_day = 31
        if end_month in [4, 6, 9, 11]:
            end_day = 30
        if end_month == 2 and end_year%4 == 0:
            # In the Julian calendar, 1500 is a leap year
            end_day = 29
        if end_month == 2 and end_year%4 != 0:
            end_day = 28


    if date_day !="":
        string_day = date_day
        start_day = int(date_day)
        if end_day == 0:
            end_day = int(date_day)
    else:
        string_day = ""
        start_day = 1
        if end_day == 0:
            if end_month in [1, 3, 5, 7, 8, 10, 12]:
                end_day = 31
            if end_month in [4, 6, 9, 11]:
                end_day = 30
            if end_month == 2 and end_year%4 == 0:
                # In the Julian calendar, 1500 is a leap year
                end_day = 29
            if end_month == 2 and end_year%4 != 0:
                end_day = 28 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[458:502]
==bpf_be_fastapi.parse_istc_old:[389:434]
    elif date_prefix in ("Between ", "between ") \
        and date_between_year != "":
#                    print("timespan with between")
        string_prefix = "between "
        string_year_between = date_between_year

        if date_year != "":
            #if the start and and the end of the time-span are not in the same year
            # print("Start of timespan has a year")
            string_year = date_year
            start_year = int(date_year)
            end_year = int(date_between_year)
        else:
#                        print("start of timespan has no year")
            string_year = ""
            start_year = int(date_between_year)
            end_year = int(date_between_year)

    elif date_year_to:
        if date_year_to[0] == "-": # Question: is this really different from 'between'?
            #(I would guess that '-' could mean that
            # the production took from a to b, and
            # between that it happened after a and before b?????)
            start_year = int(date_year)
            if len(date_year_to[1:]) == 4:
                end_year = int(date_year_to[1:])
            else:
                end_year = int("14" + date_year_to[1:])
            string_year = date_year + "-" + str(end_year)
            if date_prefix == "About " or date_prefix == "about ":
                string_prefix = "about "
                #in this case I don't change the dates, just add the 'about'
            else:
                string_prefix = ""


        if date_year_to[0] == "/":
            #This should mean exact dates from countries
            # where the year started in March/April,
            #so that a date like January 1490 is Jan 1491 in our calendar
            start_year = int(date_year)+1
            end_year = int(date_year)+1
            string_year = date_year + " (in modern calendar " + \
                str(int(date_year)+1) + ")" (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[1789:1866]
==bpf_be_fastapi.parse_gnd_old:[1342:1372]
            print(place_new)
            making_process.place = place_new
        artist = making_process.person
        if artist.name != "":
            print("Artist found")
            print(artist.name)
            artist.role = "art"
            artist_new = await identify_person(artist)
            print(artist_new)
            making_process.person = artist_new
        date = making_process.date
        if date.datestring_raw != "":
            print("Date_found")
            print(date.datestring_raw)
            try:
                date_new = parse_date.parse_manually_entered_date(date.datestring_raw)
                making_process.date = date_new
            except classes.InvalidDateStringException as d:
                print(f"String could not be divided into individual dates: {d}")
            except classes.InvalidDateException as e:
                print(f"Failed to parse date string {e}")
            except classes.InvalidMonthException as f:
                print(f"Failed to parse date string {f}")
            except classes.InvalidDayException as g:
                print(f"Failed to parse date string {g}")
            except classes.InvalidDateRangeException as h:
                print(f"{h}")


    return making_processes (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[426:474]
==bpf_be_fastapi.parse_gnd_old:[352:400]
    return potential_orgs_list





@classes.func_logger
async def identify_place(place):
    """
This function is used for every place named in the bibliographic record (place of publishing / manufacture)
It will first search if a record for this place is already in the MongoDB database, and then search in the GND
If there is an ID-number (internal or GND, the search is done for the ID-number, otherwise for the name as string, and if this fails, for the name as key-words)
Note that the GND parser combined with it suppresses all records to regions - if this mechanism is later also used for identifying regions, this might need to be changed
Since there are often many locations connected toa town (e.g., all villages in its district), I increase the number of hits from the GND to 400 and sort them alphabetically.
    """
    if place.role:
        print(place.role)
    else:
        print("No place.role")
        place.role = "pup" # I just define this for the time being.
    place.internal_id_place_type1_needed = parsing_helpers.map_role_to_place_type(place.role)
    place.chosen_candidate = 999
    print("Arrived in place_identification")
    if place.id:
#        place_found = coll.find_one({"external_id": {"$elemMatch": {"name": place.id_name, "id": place.id}}}, {"id": 1, "name_preferred": 1, "place_type1" : 1})
        place_found = db_actions.find_place(place,"external_id")
        if place_found:
            place.internal_id = place_found["id"]
            place.internal_id_preview = place_found["name_preferred"] + " (in Database)"
            place.internal_id_place_type1 = place_found["place_type1"]
#            print('Place data:')
#            print(place.internal_id_place_type1)
            place_type1_needed = parsing_helpers.map_role_to_place_type(place.role)
            #The following is a warning that a matching place has the wrong type. It should also be
            # included for all searches for names in Iconobase, but I don't build this yet since there aren't any records in it that allow my to try it out.
            # This option has not been tried out properly since places rarely come with GND numbers
            if place_type1_needed not in place.internal_id_place_type1:
                place_type1_present = ""
                for t in place.internal_id_place_type1:
                    place_type1_present = place_type1_present + "' and '" + t
                place_type1_present = place_type1_present[5:] + "'"

                place.internal_id_place_type1_comment = "This place is currently catalogued as " + place_type1_present + ", but not as '" + place_type1_needed + "'. \
                    An additional record for " + place_type1_needed + " will be produced if this record is saved. "
        else:
            if place.id_name == "GND": # I will have to create similar things for other authority files
                authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + place.id + r'%20and%20BBG%3DTg*&recordSchema=MARC21-xml&maximumRecords=100'
                print("authority_url with Gnd number: " + authority_url) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[281:317]
==bpf_be_fastapi.parse_gnd_old:[207:243]
    return potential_persons_list

@classes.func_logger
def identify_organisation(organisation):
    """
This function is used for every organisation named in the bibliographic record (printer etc.),
 and in addition for the repository of a book or manuscript. It will first search if a record
   for this organisation is already in the MongoDB database, and then search in the GND. If
   there is an ID-number (internal or GND, the search is done for the ID-number, otherwise for
     the name as string, and if this fails, for the name as key-words)
    """
#    candidates = []
    print("Starting organisatin_identification for repository")
    organisation.internal_id_org_type1_needed = parsing_helpers.map_role_to_organisation_type(organisation.role)
    organisation.chosen_candidate = 999 # For some reason, this must not be empty
    if organisation.id:
#        organisation_found = coll.find_one({"external_id": {"$elemMatch": {"name": organisation.id_name, "id": organisation.id}}}, {"id": 1, "name_preferred": 1, "org_type1": 1})
        organisation_found = db_actions.find_organisation(organisation,"external_id")
        if organisation_found:
            organisation.internal_id = organisation_found["id"]
            organisation.internal_id_preview = organisation_found["name_preferred"] + " (in Database)"
            organisation.internal_id_org_type1 = organisation_found["org_type1"]
            org_type1_needed =  parsing_helpers.map_role_to_organisation_type(organisation.role)

            #The following is a warning that a matching person has the wrong type.
            if org_type1_needed not in organisation.internal_id_org_type1:
                org_type1_present = ""
                for t in organisation.internal_id_org_type1:
                    org_type1_present = org_type1_present + "' and '" + t
                    org_type1_present = org_type1_present[5:] + "'"
                organisation.internal_id_org_type1_comment = "This organisation is currently catalogued as " + org_type1_present + ", but not as '" + org_type1_needed + "'. The latter will be added if this record has been saved. "

        else:
            if organisation.id_name == "GND": # I will have to create similar things for other authority files
                authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + organisation.id + r'%20and%20BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100'
                print(authority_url) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[403:424]
==bpf_be_fastapi.parse_gnd_old:[329:350]
    org.new_authority_id=new_authority_id
#    org_found = coll.find_one({"external_id": {"$elemMatch": {"name": "GND", "id": new_authority_id}}}, {"id": 1, "name_preferred": 1, "org_type1" : 1})
    org_found = db_actions.find_organisation(org,"GND")
    if org_found:
        print(org_found)
        potential_org.internal_id = org_found["id"]
        potential_org.internal_id_org_type1 = org_found["org_type1"]
        potential_org.preview = org_found["name_preferred"] # The date should be added, but I first have to write how it is to be parsed
        internal_id_org_type1_needed = parsing_helpers.map_role_to_organisation_type(role)
        if internal_id_org_type1_needed not in potential_org.internal_id_org_type1:
            org_type1_present = ""
            for t in potential_org.internal_id_org_type1:
                org_type1_present = org_type1_present + "' and '" + t + "'"
            org_type1_present = org_type1_present[5:]
            potential_org.internal_id_org_type1_comment = "This organisation is currently catalogued as " + org_type1_present + ", but not as '" \
                + internal_id_org_type1_needed + "'. The latter will be added if this record has been saved. "
        else:
            internal_id_org_type1_needed = ""
        potential_orgs_list.append(potential_org)
    else:
        authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + new_authority_id + r'%20and%20BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100' (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[273:293]
==bpf_be_fastapi.parse_istc_old:[259:279]
    date_prefix = ""
    date_day = ""
    date_month = ""
    date_year = ""
    date_year_to = ""
    date_between_indicator = ""
    date_between_day = ""
    date_between_month = ""
    date_between_year = ""
    string_prefix = ""
    string_day = ""
    string_month = ""
    string_year = ""
    string_day_between = ""
    string_month_between = ""
    string_year_between = ""
    start_month = 0
    start_day = 0
    start_year = 0
    end_month = 0 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_person:[221:244]
==bpf_be_fastapi.ingest_place:[98:123]
                if type_correction != "":
                    connected_org.connection_type = type_correction
                if time_correction != "":
                    connected_org.connection_time = time_correction
                if comment_correction != "":
                    connected_org.connection_comment = comment_correction

                break  # if a connection with one ID is found, the other connections would be the same.
        if not org_found and connected_org.external_id:
            if "-" in connected_org.external_id[0].id:
                gnd_internal_id = get_external_data.transform_gnd_id_with_hyphen(
                    connected_org.external_id[0].id
                )
                connected_org.external_id.insert(0, gnd_internal_id)
                print("This is the gnd_internal_id produced by the new module: ")
                print(gnd_internal_id)
                list_of_ids_to_check.append(gnd_internal_id.uri)
            else:
                list_of_ids_to_check.append(
                    connected_org.external_id[0].uri
                )  # I just use the first ID given here, since all IDs should be in VIAF

#           The following two lines are commented out until VIAF can deal with GND organisations
#            if not org_found and connected_org.external_id:
#                    list_of_ids_to_check.append(connected_org.external_id[0].uri) # I just use the first ID given here, since all IDs should be in VIAF (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[311:357]
==bpf_be_fastapi.parse_istc_old:[295:341]
        if printing_date_divided[0]:
            date_prefix = printing_date_divided[0]
        if printing_date_divided[1]:
            date_day = printing_date_divided[1]
        if printing_date_divided[2]:
            date_month = printing_date_divided[2]
        if printing_date_divided[3]:
            date_year = printing_date_divided[3]
        if printing_date_divided[4]:
            date_year_to = printing_date_divided[4]
        if printing_date_divided[5]:
            date_between_indicator = printing_date_divided[5]
        # I wonder if I even need it - probably not.
        if printing_date_divided[6]:
            date_between_day = printing_date_divided[6]
        if printing_date_divided[7]:
            date_between_month = printing_date_divided[7]
        if printing_date_divided[8]:
            date_between_year = printing_date_divided[8]

#    print("Raw date: ")
#    print(printing_date_raw)
#    print("Prefix: ")
#    if date_prefix != "":
#        print(date_prefix) #+ "x"
#    print("Day: ")
#    if date_day:
#        print(date_day) #+ "x"
#    print("Month: ")
#    if date_month:
#        print(date_month) #+ "x"
#    print("Year: ")
#    if date_year:
#        print(date_year) #+ "x"
#    print("Year - to: ")
#    if date_year_to:
#        print(date_year_to) #+ "x"
#    if date_between_day:
#        print("date_between_day: ")
#        print(date_between_day)
#    if date_between_month:
#        print("date_between_month: ")
#        print(date_between_month)
#    if date_between_year:
#        print("date_between_year: ")
#        print(date_between_year) #+ "x" (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[558:578]
==bpf_be_fastapi.parse_gnd_old:[484:504]
    place.new_authority_id=new_authority_id
    place_found = db_actions.find_place(place,"GND")
    if place_found:
#        print(place_found)
        potential_place.internal_id = place_found["id"]
        potential_place.internal_id_place_type1 = place_found["place_type1"]
        potential_place.preview = place_found["name_preferred"] + " (in Database)"
        internal_id_place_type1_needed = parsing_helpers.map_role_to_place_type(role)
        if internal_id_place_type1_needed not in potential_place.internal_id_place_type1:
            place_type1_present = ""
            for t in potential_place.internal_id_place_type1:
                place_type1_present = place_type1_present + "' and '" + t + "'"
            place_type1_present = place_type1_present[5:]
            potential_place.internal_id_place_type1_comment = "This place is currently catalogued as " + place_type1_present + ", but not as '" \
                + internal_id_place_type1_needed + "'. An additional record for " + internal_id_place_type1_needed + " will be produced if this place is selected and the record is saved. "
        potential_places_list.append(potential_place)
    else:
        authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + new_authority_id + r'%20and%20BBG%3DTg*&recordSchema=MARC21-xml&maximumRecords=100'
#        print("authority URL in additional_place_identification")
#        print(authority_url) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[259:278]
==bpf_be_fastapi.parse_gnd_old:[185:204]
    person.new_authority_id = new_authority_id
    person_found = db_actions.find_person(person,"GND")
    if person_found:
        #print(person_found)
        potential_person.internal_id = person_found["id"]
        potential_person.internal_id_person_type1 = person_found["person_type1"]
        potential_person.preview = person_found["name_preferred"] # The date should be added, but I first have to write how it is to be parsed
        internal_id_person_type1_needed =  parsing_helpers.map_role_to_person_type(role)
        if internal_id_person_type1_needed not in potential_person.internal_id_person_type1:
            person_type1_present = ""
            for t in potential_person.internal_id_person_type1:
                person_type1_present = person_type1_present + "' and '" + t + "'"
            person_type1_present = person_type1_present[5:]
            potential_person.internal_id_person_type1_comment = "This person is currently catalogued as " + person_type1_present + ", but not as '" \
                + internal_id_person_type1_needed + "'. The latter will be added if this record has been saved. "
        potential_persons_list.append(potential_person)

    else:
        authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + new_authority_id + r'%20and%20BBG%3DTp*&recordSchema=MARC21-xml&maximumRecords=100' (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[1698:1716]
==bpf_be_fastapi.parse_gnd_old:[1250:1268]
    if root[1].text:
        record_count = int(root[1].text)
    else:
        record_count = 0
    print('Number of records found')
    print(record_count)

    if record_count > 0:
        potential_places_list = gnd_parsing_place_part_of_list(root)

    if record_count > 100:
        record_count = record_count-100
        start_record = 101
        authority_url_basis = authority_url + "&startRecord="

#         authority_url_basis = authority_url[:-18] + "startRecord="
        while record_count > 0:
            authority_url = authority_url_basis + str(start_record) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_person:[290:306]
==bpf_be_fastapi.ingest_place:[244:264]
                    print("location with hyphen found")
                    print("sending id to transform_gnd_id_with_hyphen")
                    print(connected_location.external_id[0].id)
                    gnd_internal_id = get_external_data.transform_gnd_id_with_hyphen(
                        connected_location.external_id[0].id
                    )
                    print("This is the gnd_internal_id produced by the new module: ")
                    print(gnd_internal_id)
                    connected_location.external_id.insert(0, gnd_internal_id)
                    list_of_ids_to_check.append(gnd_internal_id.uri)
                else:
                    list_of_ids_to_check.append(
                        connected_location.external_id[0].uri
                    )  # I just use the first ID given here, since all IDs should be in VIAF

    # Here, I send the list of all collected IDs for which I need a VIAF ID to the function that contacts VIAF. (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[1718:1788]
==bpf_be_fastapi.parse_gnd_old:[1271:1341]
            additional_potential_places_list = gnd_parsing_place_part_of_list(root)
            potential_places_list = potential_places_list + additional_potential_places_list
            record_count = record_count - 100
            start_record = start_record + 100
    if potential_places_list:
#        print("List of potential places: ")
#        print(potential_places_list)
        for place in potential_places_list:
            if search_term in place.name_preferred or len(potential_places_list) == 1:
#                print(place.name_preferred)
                potential_places_list_complete.append(place)
    return potential_places_list_complete


#person = Person()
#person.id_name = "GND"
#person.id = "11900108X" #Lautensack
#person.role = "prt"
#person.id = "118650130" # Aristotle
#person.id = "118780743" #Louis XVIII
#person.name = "Lautensack, Paul"
#person.name = "Rubens, Peter Paul"
#person.name = "Andreas Asula"
#record = person_identification(person)
#organisation = Organisation()
#organisation.id_name = "GND"
#organisation.id = "2133444-4"
#record = organisation_identification(organisation)
#authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D' + organisation.id + r'%20and%20BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100'
#print(authority_url)
#record = gnd_parsing_organisation(authority_url)
#print(record)
#organisation.name = "Bamberg, Staatsbibliothek"
#authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=Koe%3DBamberg,%20Staatsbibliothek%20%20and%20BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100'
#record = gnd_parsing_organisation(authority_url)
#record = organisation_identification(organisation)
#print(record)
#authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D4086808-4%20and%20BBG%3DTg*&recordSchema=MARC21-xml&maximumRecords=100'
#place = Place()
#place.id_name = "GND"
#place.id = "4086808-4"
#place.name = "Frankfurt, Main"
#x = place_identification(place)

#print(x)


@classes.func_logger
async def identify_making_process(making_processes):
    """
    This module has bene primarily made for parsing information about the making process of a manuscript or printed book
    that had been entered manually during the ingest process.
    If such information is added when working on individual records, it might be possible to adopt this module, but one would probably rather go directly
    to parsing the individual parts of it.
    Manuscripts have by default one Making Process, Printed Books two (in theory three, but the third, printing, is already defined by bibliographic data
    and hence would not be added here).
    Each making process has a number (currently as integer, although I wonder if one should not rather use a string to allow for e.g. 1a, 1b etc),
    a process_type (the activity, e.g. design, blockcutting, etc.), and a process qualifier (e.g., none, attributed, follower of, etc.) - these two
    will eventually probably belong drop-down fields.
    It also has three fields that need parsing - one for a person (normally the artist), one for a place, and one for a date.
    The person will be parsed similar to persons conntected to a book - but instead of the GND, the Getty ULAN would be the preferred source of information.
    The place will be parsed as places conntected to a book (also here historical names), and the GND will also here be the principal source.
    The date will be entered according to relatively simple rules that the editors would have to learn and would be parsed in a separate routine.

    Eventually, two more fields will be added - the Medium, and the Illustrated Text.
    """
    for making_process in making_processes:
        place = making_process.place
        if place.name != "":
            place.role = "Place of Making" (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_person:[419:433]
==bpf_be_fastapi.ingest_place:[369:383]
            print(
                "now processing connected organisation " + connected_organisation.name
            )
            new_connected_organisation = classes.Edge()
            new_connected_organisation.id = connected_organisation.id
            new_connected_organisation.external_id = connected_organisation.external_id
            new_connected_organisation.name = connected_organisation.name
            new_connected_organisation.connection_type = (
                connected_organisation.connection_type
            )
            new_connected_organisation.connection_time = (
                connected_organisation.connection_time
            )
            # For connection time see above under new connected person (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1012:1026]
==bpf_be_fastapi.parse_gnd:[1082:1096]
        subfields = find_subfields(datafield,"4")
        if subfields:
            if "http" not in subfields[0]:
                ec.connection_type = subfields[0] # Once one can give connection_types for both directions,
                # here the correct connection types in both directions have to be created
                ec.relationB = subfields[0]
        subfields = find_subfields(datafield,"9")
        if subfields:
            for subfield in subfields:
                if subfield[0:2] == "v:":
                    ec.connection_comment = subfield[2:]
                elif subfield[0:2] == "Z:":
                    ec.connection_time = subfield[2:]
 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1087:1101]
==bpf_be_fastapi.parse_gnd:[1007:1021]
        subfields = find_subfields(datafield,"4")
        if subfields:
            if "http" not in subfields[0]:
                ec.connection_type = subfields[0] # Once one can give connection_types for both directions,
                # here the correct connection types in both directions have to be created
                ec.relationB = subfields[0]
        subfields = find_subfields(datafield,"9")
        if subfields:
            for subfield in subfields:
                if subfield[0:2] == "v:":
                    ec.connection_comment = subfield[2:]
                elif subfield[0:2] == "Z:":
                    ec.connection_time = subfield[2:]
 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[990:1001]
==bpf_be_fastapi.parse_gnd:[1063:1074]
        ec=classes.Edge()
        subfields = find_subfields(datafield,"0")
        if subfields:
            for subfield in subfields:
                external_reference = classes.ExternalReference()
                external_reference.name = "GND"
                if subfield[0:8] == "(DE-588)" or subfield[0:8] == "(DE-101)":
                    external_reference.external_id = subfield[8:]
                else:
                    external_reference.external_id = subfield
                external_reference.uri = r'https://d-nb.info/gnd/' + external_reference.external_id (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1068:1079]
==bpf_be_fastapi.parse_gnd:[985:996]
        ec=classes.Edge()
        subfields = find_subfields(datafield,"0")
        if subfields:
            for subfield in subfields:
                external_reference = classes.ExternalReference()
                external_reference.name = "GND"
                if subfield[0:8] == "(DE-588)" or subfield[0:8] == "(DE-101)":
                    external_reference.external_id = subfield[8:]
                else:
                    external_reference.external_id = subfield
                external_reference.uri = r'https://d-nb.info/gnd/' + external_reference.external_id (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[535:555]
==bpf_be_fastapi.parse_gnd_old:[461:481]
            print("Number or additional potential candidates: ")
            print(len(additional_potential_candidates))
            for additional_candidate in additional_potential_candidates:
                if additional_candidate not in place.potential_candidates:
                    place.potential_candidates.append(additional_candidate)
    place.potential_candidates = sorted(place.potential_candidates, key = lambda candidate : candidate.preview)
    if len(place.potential_candidates) == 1: # If there is only one entry for this person, it is by default selected (although the user can also run a new search, once this is established)
        place.chosen_candidate = 0
    return place


@classes.func_logger
def identify_additional_place(new_authority_id, role):
    """
This function is used for any additional authority records that are suggested as identifications for organisations connected to a book.
Normally, they are parsed with gnd_parsing_place - but beforehand it is checked if they are already in Iconobase and have not been found for whatever reason.
Currently all records must come from the GND - if other authority files are included, this function has to be changed.
    """
    new_authority_id = new_authority_id.strip()
    potential_places_list = [] (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1871:1883]
==bpf_be_fastapi.parse_vd17_vd18:[611:627]
    datafields=record.findall("{*}recordData/{*}record/{*}datafield[@tag='"+tag_id+"']")
    return datafields

def find_subfields(datafield,subfield_id):
    r=[]
    subfields=datafield.findall("{*}subfield")
    for subfield in subfields:
        key= subfield.get("code")
        value=subfield.text
        if key == subfield_id:
            r.append(value)
    return r (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[523:534]
==bpf_be_fastapi.parse_gnd_old:[449:460]
            print("Number of 'portential candidates': ")
            print(len(place.potential_candidates))
#       I actually do not believe that one needs a words search for places
            name_divided = place_name_search.split("%20")
            name_query = ""
            for word in name_divided:
                if word != "":
                    search_phrase = r"Geo%3D" + word + r"%20and%20" # I don't get it, but the thing only works if the "=" is written as such and not as Percent code. Above, it is different.
                    name_query = name_query + search_phrase
                    print ("name query:" + name_query)
            authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=' + name_query + r'BBG%3DTg*&recordSchema=MARC21-xml&maximumRecords=100' (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[326:337]
==bpf_be_fastapi.parse_gnd_old:[252:263]
            candidate.internal_id = candidate_result["id"]
            candidate.name_preferred = candidate_result["name_preferred"]
            candidate.preview = candidate_result["name_preferred"] + " (in Database)"
            candidate.internal_id_org_type1 = candidate_result["org_type1"]
            print("orgtype1 in search for name_preferred: ")
            print(candidate.preview)
            print(candidate.internal_id_org_type1)
            organisation.potential_candidates.append(candidate)
#        candidates_result = coll.find({"name_variant" : organisation.name}, {"id": 1, "name_preferred" : 1, "org_type1" : 1}) #I search first for the preferred names (assuming that it is more likely there will be a good match, and only later for the variants)
        candidates_result = db_actions.find_organisation(organisation,"name_variant")
        for candidate_result in candidates_result: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[532:543]
==bpf_be_fastapi.parse_istc_old:[444:456]
        string_month = month_names[date_month]
        number_month = month_numbers[date_month]
        start_month = int(number_month)
        if end_month == 0:
            #thus, if there is no indication of an end month, as in a timespan
            end_month = int(number_month)
    else:
        string_month = ""
        start_month = 1
        if end_month == 0: # If it has not been defined elsewhere
            end_month = 12
 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[96:137]
==bpf_be_fastapi.parse_gnd:[97:138]
    print("input gnd id:"+gnd_id_in)
    if gnd_id_in:
        xx = classes.Role.find(classes.Role.entity_and_connections.entity.gnd_id == gnd_id_in,fetch_links=True)
        role_in_db = await xx.to_list()
        print("Search result")
        print(role_in_db)
    # This makes little sense up to now since no record from ISTC comes with a GND ID.
    # This will be needed later, when also records of the VD17 and VD18 are being parsed.


#    person.chosen_candidate = 999
    # For some reason, I cannot return the form when
    #'chosen candidate' is empty. Hence, I put this in as a default setting.
#    if person.id:
#        person_found = coll.find_one({"external_id": {"$elemMatch":
# {"name": person.id_name, "id": person.id}}}, {"id": 1, "person_type1": 1, "name_preferred": 1})
#        person_found = await db_actions.find_person(person,"external_id")
#        if person_found:
            #print(person_found)
#            person.internal_id = person_found["id"]
#            person.internal_id_person_type1 = person_found["person_type1"]

#            person.internal_id_preview = person_found["name_preferred"] + " (in Database)"
            # The date should be added, but I first have to write how it is to be parsed
        if role_in_db:
#        role_in_db[0].comment="(in Database)"
            found_person=True
            print("found person")

            #The following is a warning that a matching person has the wrong type.
    # if role_in.role not i

    #         if person.internal_id_person_type1_needed not in person.internal_id_person_type1:
    #             person_type1_present = ""
    #             for t in person.internal_id_person_type1:
    #                 person_type1_present = person_type1_present + "' and '" + t + "'"
    #             person_type1_present = person_type1_present[5:]
    #             person.internal_id_person_type1_comment = "This person is currently catalogued as " + person_type1_present + ", but not as '" + person.internal_id_person_type1_needed + "'. The latter will be added if this record has been saved. "


#async def search_for_person_candidates(): (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_person:[347:356]
==bpf_be_fastapi.ingest_place:[304:313]
        if connected_location.external_id:
            if connected_location.external_id[0].uri in list_of_viaf_ids:
                location_viaf_url = list_of_viaf_ids[
                    connected_location.external_id[0].uri
                ]
                place_id = classes.ExternalReference()
                place_id.name = "viaf"
                place_id.uri = location_viaf_url
                place_id.id = location_viaf_url[21:] (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[113:123]
==bpf_be_fastapi.ingest_place:[98:108]
                    if type_correction != "":
                        connected_org.connection_type = type_correction
                    if time_correction != "":
                        connected_org.connection_time = time_correction
                    if comment_correction != "":
                        connected_org.connection_comment = comment_correction

                    break # if a connection with one ID is found, the other connections would be the same.
            if not org_found and connected_org.external_id:
                if "-" in connected_org.external_id[0].id: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[909:919]
==bpf_be_fastapi.parse_gnd:[1467:1475]
    variants = []
    for datafield in datafields:
        name_variant = ""


        subfields = find_subfields(datafield,"a")
        if subfields:
            name_variant = subfields[0]
        subfields = find_subfields(datafield,"b")
        if subfields: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1472:1480]
==bpf_be_fastapi.parse_gnd:[904:914]
    variants = []
    for datafield in datafields:
        name_variant = ""
        subfields = find_subfields(datafield,"a")
        if subfields:
            name_variant = subfields[0]
        subfields = find_subfields(datafield,"b")
        if subfields: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[475:522]
==bpf_be_fastapi.parse_gnd_old:[401:448]
    else:
        print("place name has no ID")
        place.name = place.name.strip()
#        candidates_result = coll.find({"name_preferred" : place.name}, {"id": 1, "name_preferred" : 1, "place_type1" : 1})
        candidates_result = db_actions.find_place(place,"name_preferred")
        for candidate_result in candidates_result:
            candidate = classes.Node()
            candidate.internal_id = candidate_result["id"]
            candidate.name_preferred = candidate_result["name_preferred"] # I need this to create previews for places of making
            print("candidate found through name search in database (preferred name)" + candidate.internal_id)
            candidate.preview = candidate_result["name_preferred"] + " (in Database)"
            candidate.internal_id_place_type1 = candidate_result["place_type1"]
            place.potential_candidates.append(candidate)
#        candidates_result = coll.find({"name_variant" : place.name}, {"id": 1, "name_preferred" : 1, "place_type1" : 1}) #I search first for the preferred names (assuming that it is more likely there will be a good match, and only later for the variants)
        candidates_result = db_actions.find_place(place,"name_variant")
        for candidate_result in candidates_result:
            candidate = classes.Node()
            candidate.internal_id = candidate_result["id"]
            print("candidate found through name search in database (variant name name)" + candidate.internal_id)
            candidate.preview = candidate_result["name_preferred"] + " (in Database)"
            candidate.internal_id_place_type1 = candidate_result["place_type1"]

            if candidate not in place.potential_candidates:
                place.potential_candidates.append(candidate)
                # Warning if the place has not the right type:
            for candidate in place.potential_candidates:
                print(candidate.preview)
                print(candidate.internal_id_place_type1)
                print(place.internal_id_place_type1_needed)
                if place.internal_id_place_type1_needed not in candidate.internal_id_place_type1:
                    place_type1_present = ""
                    for t in candidate.internal_id_place_type1:
                        place_type1_present = place_type1_present + "' and '" + t + "'"
                    place_type1_present = place_type1_present[5:]


                    candidate.internal_id_place_type1_comment = "This place is currently catalogued as " + place_type1_present + ", but not as '" + place.internal_id_place_type1_needed + "'. \
                    An additional record for " + place.internal_id_place_type1_needed + " will be produced if this place is selected and the record is saved. "

        if not place.potential_candidates: #if nothing has been found
            print("Candidate not found in database")
            place_name_search = place.name.strip()
            for old, new in parsing_helpers.url_replacement.items():
                place_name_search = place_name_search.replace(old, new)
                #print("Search term for place :x" + place_name_search + "x")
            authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=Geo%3D' + place_name_search + r'%20and%20BBG%3DTg*&recordSchema=MARC21-xml&maximumRecords=100'
            print('URL for place name search : '+ authority_url) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[384:401]
==bpf_be_fastapi.parse_gnd_old:[310:327]
            for candidate in new_potential_candidates:
                if candidate not in organisation.potential_candidates: #I need this distinction because I perform both a string and a keyword search, and both may yield the same results
                    organisation.potential_candidates.append(candidate)
    if len(organisation.potential_candidates) == 1: # If there is only one entry for this organisation, it is by default selected (although the user can also run a new search, once this is established)
        organisation.chosen_candidate = 0

    return organisation

@classes.func_logger
def identify_additional_organisation(new_authority_id, role):
    """
This function is used for any additional authority records that are suggested as identifications for organisations connected to a book.
Normally, they are parsed with gnd_parsing_organisation - but beforehand it is checked if they are already in Iconobase and have not been found for whatever reason.
Currently all records must come from the GND - if other authority files are included, this function has to be changed.
    """
    new_authority_id = new_authority_id.strip()
    potential_orgs_list = [] (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[148:156]
==bpf_be_fastapi.ingest_person:[276:285]
                    if type_correction != "":
                        connected_location.connection_type = type_correction
                    if time_correction != "":
                        connected_location.connection_time = time_correction
                    if comment_correction != "":
                        connected_location.connection_comment = comment_correction
                    break # if a connection with one ID is found, the other connections would be the same.
            if not location_found and connected_location.external_id: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[558:569]
==bpf_be_fastapi.parse_istc_old:[482:491]
            if end_month in [1, 3, 5, 7, 8, 10, 12]:
                end_day = 31
            if end_month in [4, 6, 9, 11]:
                end_day = 30
            if end_month == 2 and end_year%4 == 0:
                # In the Julian calendar, 1500 is a leap year
                end_day = 29
            if end_month == 2 and end_year%4 != 0:
                end_day = 28 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[578:587]
==bpf_be_fastapi.parse_istc_old:[462:473]
            if end_month in [1, 3, 5, 7, 8, 10, 12]:
                end_day = 31
            if end_month in [4, 6, 9, 11]:
                end_day = 30
            if end_month == 2 and end_year%4 == 0:
                # In the Julian calendar, 1500 is a leap year
                end_day = 29
            if end_month == 2 and end_year%4 != 0:
                end_day = 28 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[190:198]
==bpf_be_fastapi.ingest_place:[285:293]
        if connected_person.external_id:
            if connected_person.external_id[0].uri in list_of_viaf_ids:
                person_viaf_url = list_of_viaf_ids[connected_person.external_id[0].uri]
                person_id = classes.ExternalReference()
                person_id.name = "viaf"
                person_id.uri = person_viaf_url
                person_id.id = person_viaf_url[21:]
                connected_person.external_id.append(person_id) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[87:97]
==bpf_be_fastapi.ingest_place:[49:58]
                    if type_correction != "":
                        connected_person.connection_type = type_correction
                    if time_correction != "":
                        connected_person.connection_time = time_correction
                    if comment_correction != "":
                        connected_person.connection_comment = comment_correction

                    break # if a connection with one ID is found, the other connections would be the same.

            if not person_found and connected_person.external_id: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[142:202]
==bpf_be_fastapi.parse_gnd:[143:203]
        authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D'\
              + role_in.entity_and_connections.entity.gnd_id\
                  + r'%20and%20BBG%3DTp*&recordSchema=MARC21-xml&maximumRecords=100'
        print("url for person search: ")
        print(authority_url)
#        role_in.entity_and_connections.connected_persons = await find_and_parse_person_gnd(authority_url)
        person_found=True # This variable doesn't exist. Furthermore, there has not yet been any search
        print(role_in.model_dump())

#     else:

#         person.name = person.name.strip()
#         for old, new in parsing_helpers.encoding_list.items():
#             person.name = person.name.replace(old, new)

#         candidates_result = coll.find({"name_preferred" : person.name}, {"id": 1, "name_preferred" : 1, "person_type1" : 1})
# #        candidates_result = await db_actions.find_person(person,"name_preferred")
#         for candidate_result in candidates_result:
#             candidate = classes.Person()
#             candidate.internal_id = candidate_result["id"]
#             candidate.name_preferred = candidate_result["name_preferred"]
#             candidate.internal_id_person_type1 = candidate_result["person_type1"]
#             candidate.preview = candidate.name_preferred + " (in Database)" # The years should be added once I have them
#             print("Found as preferred name")
#             print(candidate.internal_id)
#             print(candidate.name_preferred)
#             print(candidate.internal_id_person_type1)
#             person_in.person_selection.append(candidate)
#         candidates_result = coll.find({"name_variant" : person.name}, {"id": 1, "name_preferred" : 1, "person_type1" : 1})
# #        candidates_result = db_actions.find_person(person,"name_variant")
#         #I search first for the preferred names (assuming that it is more likely there will be a good match, and only later for the variants)
#         for candidate_result in candidates_result:
#             candidate = classes.Person()
#             candidate.internal_id = candidate_result["id"]
#             candidate.name_preferred = candidate_result["name_preferred"]
#             candidate.internal_id_person_type1 = candidate_result["person_type1"]
#             candidate.preview = candidate.name_preferred + " (in Database)" # Also here, the years should be added
#             print("Found as variant: ")
#             print(candidate.internal_id)
#             print(candidate.name_preferred)
#             print(candidate.internal_id_person_type1)
#             candidate_duplicate = False
#             for extant_candidate in person_in.person_candidates:
#                 if extant_candidate.name_preferred == candidate.name_preferred:
#                     candidate_duplicate = True
#             if not candidate_duplicate:
# #                cc=classes.SelectionCandidate()
# #                cc.person=candidate
# #                person_in.person_selection.append(cc)
#                 print(person.potential_candidates)


#             for candidate in person_in.person_candidates:
#                 if person.internal_id_person_type1_needed not in candidate.internal_id_person_type1:
#                     person_type1_present = ""
#                     for t in candidate.internal_id_person_type1:
#                         person_type1_present = person_type1_present + "' and '" + t + "'"
#                     person_type1_present = person_type1_present[5:]
#                     candidate.internal_id_person_type1_comment = "This person is currently catalogued as " + person_type1_present + ", but not as '" + person.internal_id_person_type1_needed + "'. The latter will be added if this record has been saved. "
 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[374:383]
==bpf_be_fastapi.parse_gnd_old:[300:309]
            name_divided = organisation_name_search.split("%20")
            name_query = ""
            for word in name_divided:
                if word != "":
                    search_phrase = r"Koe=" + word + r"%20and%20" # I don't get it, but the thing only works if the "=" is written as such and not as Percent code. Above, it is different.
                    name_query = name_query + search_phrase
#                    print ("name query:" + name_query)
            authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=' + name_query + r'BBG%3DTb*&recordSchema=MARC21-xml&maximumRecords=100'
 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[218:226]
==bpf_be_fastapi.parse_gnd_old:[149:156]
                name_divided = person_name_search.split("%20")
                name_query = ""
                for word in name_divided:
                    if word != "": #necessary, otherwise there will be error messages
                        search_phrase = r"Per=" + word + r"%20and%20" # I don't get it, but the thing only works if the "=" is written as such and not as Percent code. Above, it is different.
                        name_query = name_query + search_phrase
                authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=' + name_query + r'BBG%3DTp*&recordSchema=MARC21-xml&maximumRecords=100' (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[199:207]
==bpf_be_fastapi.ingest_person:[337:346]
        if connected_org.external_id:
            if connected_org.external_id[0].uri in list_of_viaf_ids:
                org_viaf_url = list_of_viaf_ids[connected_org.external_id[0].uri]
                org_id = classes.ExternalReference()
                org_id.name = "viaf"
                org_id.uri = org_viaf_url
                org_id.id = org_viaf_url[21:]
                connected_org.external_id.append(org_id) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[520:530]
==bpf_be_fastapi.parse_istc_old:[434:444]
    if date_between_month !="":
        string_month_between = month_names[date_between_month]
        number_month_between = month_numbers[date_between_month]
        end_month = int(number_month_between)
    elif date_between_year != "":
        # Thus, there is no end month but an end year in this case,
        # the end month has to be December.
        end_month = 12

    if date_month != "": (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[510:517]
==bpf_be_fastapi.parse_istc_old:[252:259]
    month_names = {"Jan. " : "January ", "Feb. " : "February ", "Mar. " : "March ", \
                   "Apr. ": "April", "May " : "May ", "June " : "June ", "July " : "July ", \
                    "Aug. " : "August ", "Sep. " : "September ", "Sept. " : "September ", \
                    "Oct. " : "October ", "Nov. " : "November ", "Dec. " : "December "}
    month_numbers = {"Jan. " : 1, "Feb. " : 2, "Mar. " : 3, "Apr. ": 4, "May " : 5, "June " : 6, \
                     "July " : 7, "Aug. " : 8, \
                    "Sep. " : 9, "Sept. " : 9, "Oct. " : 10, "Nov. " : 11, "Dec. " : 12} (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[94:105]
==bpf_be_fastapi.parse_istc_old:[120:131]
            if imprint_name_long:
#                print("imprint_name_long before replacement: " + imprint_name_long)
                imprint_name_long = imprint_name_long.replace("and for", "and")
                # sometimes, the "for" is repeated for a second publisher, what is confusing
#                print("imprint_name_long after replacement: " + imprint_name_long)
                if " for " in imprint_name_long:
                    # in this case there are both a printer and a publisher
                    imprint_name_long_divided = imprint_name_long.split(" for ")
                    printer_name_long = imprint_name_long_divided[0]
                    publisher_name_long = imprint_name_long_divided[1]
                    printer_name_long = printer_name_long.strip(",") (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_person:[391:399]
==bpf_be_fastapi.ingest_place:[49:57]
                        if type_correction != "":
                            connected_person.connection_type = type_correction
                        if time_correction != "":
                            connected_person.connection_time = time_correction
                        if comment_correction != "":
                            connected_person.connection_comment = comment_correction
                        break
 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_person:[360:369]
==bpf_be_fastapi.ingest_place:[321:330]
            if (
                not connected_person.id and connected_person.external_id
            ):  # If there is already an id, no 'stitching' is required
                for external_id in connected_person.external_id:
                    if (
                        external_id.name != "DNB"
                    ):  # If it is, the connection has been made earlier
                        # This is 'stitching' step 1 for the records that can only be connected through VIAF
                        #                        person_found = coll.find_one({"external_id": {"$elemMatch": {"name": external_id.name, "id": external_id.id}}}, {"id": 1, "name_preferred" : 1, "sex" : 1, "connected_persons" : 1}) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[285:293]
==bpf_be_fastapi.ingest_place:[411:419]
                connected_location.connection_comment = "wohnort"

            new_connected_location = classes.Edge()
            new_connected_location.id = connected_location.id
            new_connected_location.external_id = connected_location.external_id
            new_connected_location.name = connected_location.name
            new_connected_location.connection_type = connected_location.connection_type
            new_connected_location.connection_time = connected_location.connection_time (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[199:206]
==bpf_be_fastapi.ingest_place:[294:301]
        if connected_org.external_id:
            if connected_org.external_id[0].uri in list_of_viaf_ids:
                org_viaf_url = list_of_viaf_ids[connected_org.external_id[0].uri]
                org_id = classes.ExternalReference()
                org_id.name = "viaf"
                org_id.uri = org_viaf_url
                org_id.id = org_viaf_url[21:] (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[235:246]
==bpf_be_fastapi.ingest_place:[98:106]
                        if type_correction != "":
                            connected_org.connection_type = type_correction
                        if time_correction != "":
                            connected_org.connection_time = time_correction
                        if comment_correction != "":
                            connected_org.connection_comment = comment_correction

                        break

# Similar features have to be added for connected organisations and places, once this is possible.
 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[1866:1874]
==bpf_be_fastapi.parse_vd17_vd18:[611:623]
    datafields=record.findall("{*}recordData/{*}record/{*}datafield[@tag='"+tag_id+"']")
    return datafields

def find_subfields(datafield,subfield_id):
    """
    Returns a list of all subfields of a datafield in a MARCXML
    Document with the same subfield number
    """
    r=[]
    subfields=datafield.findall("{*}subfield")
    for subfield in subfields:
        key= subfield.get("code") (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1028:1066]
==bpf_be_fastapi.parse_gnd:[1097:1139]
            connections.append(ec)
    print(connections)
    return connections


@classes.func_logger
def gnd_record_get_connected_orgs(record):
    """
#                 case "510":
#                     conn_org = classes.EntityConnection()
#                     conn_org.external_id = []
#                     for step2 in step1:
#                         match step2.get('code'):
#                             case "0":
#                                 if step2.text[0:8] == "(DE-588)":
#                                     conn_id = classes.ExternalReference()
#                                     conn_id.name = "GND"
#                                     conn_id.external_id = step2.text[8:]
#                                     conn_id.uri =  r'https://d-nb.info/gnd/' + conn_id.external_id
#                                     conn_org.external_id.append(conn_id)
#                             case "a":
#                                 conn_org.name = step2.text
#                             case "b": #for sub-units of organisations - no clue if this will ever happen in my circumstances
#                                 conn_org.name = conn_org.name + " (" + step2.text + ")"
#                             case "4":
#                                 if step2.text[0:4] != "http": # in this subfield are both the relation codes and a URI for the relation codes, I don't need the latter
#                                     conn_org.connection_type = step2.text
#                             case "9":
#                                 if step2.text[0:2] == "v:":
#                                     conn_org.connection_comment = step2.text[2:]
#                                 if step2.text[0:2] == "Z:":
#                                     conn_org.connection_time = step2.text[2:]
#                     pe.connected_organisations.append(conn_org)

    """
    connections = []
    datafields = find_datafields(record,"500")
    for datafield in datafields: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1102:1144]
==bpf_be_fastapi.parse_gnd:[1023:1061]
        connections.append(ec)
    print(connections)
    return connections


@classes.func_logger
def gnd_record_get_connected_places(record):
    """
    #                 case "551":
#                     conn_pl = classes.EntityConnection()
#                     conn_id = classes.ExternalReference()
#                     for step2 in step1:
#                         match step2.get('code'):
#                             case "0":
#                                 if step2.text[0:8] == "(DE-588)":
#                                     conn_id.name = "GND"
#                                     conn_id.external_id = step2.text[8:]
#                                     conn_pl.external_id.append(conn_id)
#                                     conn_id.uri =  r'https://d-nb.info/gnd/' + conn_id.external_id
#                             case "a":
#                                 conn_pl.name = step2.text
#                             case "g":
#                                 conn_pl.name = conn_pl.name + " (" + step2.text + ")"
#                             case "4":
#                                 if step2.text[0:4] != "http": # in this subfield are both the relation codes and a URI for the relation codes, I don't need the latter
#                                     conn_pl.connection_type = step2.text
#                             case "9":
#                                 if step2.text[0:2] == "v:":
#                                     conn_pl.connection_comment = step2.text[2:]
#                                 if step2.text[0:2] == "Z:":
#                                     conn_pl.connection_time = step2.text[2:]
#                     if conn_pl.connection_type == "ortg":
#                         ortg_preview = ", born in " + conn_pl.name
#                     if conn_pl.connection_type == "orts":
#                         orts_preview = ", died in " + conn_pl.name
#                     if conn_pl.connection_type == "ortw":
#                         ortw_preview = ", active in " + conn_pl.name
#                     pe.connected_locations.append(conn_pl)
"""
    connections = []
    datafields = find_datafields(record,"500")
    for datafield in datafields: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[814:820]
==bpf_be_fastapi.parse_gnd:[1431:1437]
    for datafield in datafields:
        subfields = find_subfields(datafield,"a")
        if subfields:
            name_preferred = subfields[0]
        subfields = find_subfields(datafield,"b")
        if subfields: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1436:1442]
==bpf_be_fastapi.parse_gnd:[812:818]
    for datafield in datafields:
        subfields = find_subfields(datafield,"a")
        if subfields:
            name_preferred = subfields[0]
        subfields = find_subfields(datafield,"b")
        if subfields: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[699:709]
==bpf_be_fastapi.parse_gnd:[706:716]
    external_reference = classes.ExternalReference()
    external_reference.name="GND intern"
    external_reference.external_id=controlfields[0].text
    external_references.append(external_reference)

#   Annoyingly, the search also finds IDs from the old database PND. If it is possible that a PND ID is the same as the GND ID of a
#   different record, I have to include a function to delete this record from the results (I am enquiring if this is the case)

    print("internal GND id: ")
    print(external_references) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[584:590]
==bpf_be_fastapi.parse_gnd:[606:612]
    authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D'\
                    + gnd_id\
                    + r'%20and%20BBG%3DTp*&recordSchema=MARC21-xml&maximumRecords=100'
    content=await get_external_data.get_web_data(authority_url)
    root = etree.XML(content)
    records=root.find("records", namespaces=root.nsmap) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[604:610]
==bpf_be_fastapi.parse_gnd:[586:592]
    authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=NID%3D'\
                    + gnd_id\
                    + r'%20and%20BBG%3DTp*&recordSchema=MARC21-xml&maximumRecords=100'
    content=await get_external_data.get_web_data(authority_url)
    root = etree.XML(content)
    records=root.find("records", namespaces=root.nsmap) (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[206:216]
==bpf_be_fastapi.parse_gnd:[207:217]
        for old, new in parsing_helpers.url_replacement.items():
            person_name_search = person_name_search.replace(old, new)
        authority_url = r'https://services.dnb.de/sru/authorities?version=1.1&operation=searchRetrieve&query=Per%3D' + person_name_search + r'%20and%20BBG%3DTp*&recordSchema=MARC21-xml&maximumRecords=100'
        print(authority_url)
#        person_in.person_candidates = parse_person_gnd(authority_url)

    if not found_person:
        # This search shoudl only happen if the search before did not work. It should likewise exclude artists.
            # if not person_in.person_candidates: #if still nothing has been found, a keyword search is performed instead of a string search.
        print("Searching in GND by name") (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[318:325]
==bpf_be_fastapi.parse_gnd_old:[244:251]
    else:
        print("No repository ID")
        organisation.name = organisation.name.strip()
#        candidates_result = (coll.find({"name_preferred" : organisation.name}, {"id": 1, "name_preferred" : 1, "org_type1" : 1}))
        candidates_result = db_actions.find_organisation(organisation,"name")
        print("Search for repository candidate completed")
        for candidate_result in candidates_result: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_person:[523:529]
==bpf_be_fastapi.ingest_place:[481:487]
                        )
                        new_connection = classes.Edge()
                        new_connection.id = far_record["id"]
                        new_connection.name = far_record["name_preferred"]
                        new_connection.connection_type = (
                            person_relations.relation_correspondence( (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_person:[407:415]
==bpf_be_fastapi.ingest_place:[359:367]
            new_connected_person.name = connected_person.name
            new_connected_person.connection_type = connected_person.connection_type
            new_connected_person.connection_time = connected_person.connection_time
            new_connected_person.connection_comment = (
                connected_person.connection_comment
            )
            # In theory, one should also replace this time string through a proper date object However, since I don't assume that anything will ever be made with
            # this information apart from displaying it, this is unnecessary or at least not urgent. (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[148:154]
==bpf_be_fastapi.ingest_place:[233:239]
                    if type_correction != "":
                        connected_location.connection_type = type_correction
                    if time_correction != "":
                        connected_location.connection_time = time_correction
                    if comment_correction != "":
                        connected_location.connection_comment = comment_correction (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[20:26]
==bpf_be_fastapi.ingest_place:[131:137]
    list_of_ids_to_check = []
    new_record_viaf_id = ""
    new_record_gnd_id = ""
    person_found = {}
    org_found = {}
    location_found = {} (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1479:1497]
==bpf_be_fastapi.parse_gnd:[1677:1691]
        if subfields:
            name_variant = name_variant + " (" + subfields[0] + ")"
        if name_variant not in variants:
            variants.append(name_variant)
    return (variants)



async def parse_place_gnd(authority_url):
    """
\todo

    """
 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1682:1696]
==bpf_be_fastapi.parse_gnd:[1474:1492]
        if subfields:
            name_variant = name_variant + " (" + subfields[0] + ")"
        if name_variant not in variants:
            variants.append(name_variant)
    return (variants)



async def parse_place_gnd(authority_url):
    """
\todo

    """
 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[910:917]
==bpf_be_fastapi.parse_gnd:[1663:1670]
    for datafield in datafields:
        name_variant = ""
        subfields = find_subfields(datafield,"a")
        if subfields:
            name_variant = subfields[0]
        # I don't know if the subfields i, x and z ever contain any relevant information,
        # so I add them just in case. (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1668:1675]
==bpf_be_fastapi.parse_gnd:[905:912]
    for datafield in datafields:
        name_variant = ""
        subfields = find_subfields(datafield,"a")
        if subfields:
            name_variant = subfields[0]
        # I don't know if the subfields i, x and z ever contain any relevant information,
        # so I add them just in case. (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[631:640]
==bpf_be_fastapi.parse_gnd:[1351:1356]
    result = []
    content=await get_external_data.get_web_data(authority_url)
    root = etree.XML(content)
    records=root.find("records", namespaces=root.nsmap)
    for record in records: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd copy:[1356:1361]
==bpf_be_fastapi.parse_gnd:[633:642]
    result = []
    content=await get_external_data.get_web_data(authority_url)
    root = etree.XML(content)
    records=root.find("records", namespaces=root.nsmap)
#    print(records)
#    print(records.tag)
#    tag_id='400'
#    subfield_code="a"
    for record in records: (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_gnd:[1691:1696]
==bpf_be_fastapi.parse_gnd_old:[1242:1247]
    potential_places_list = []
    potential_places_list_complete = []
    search_term = authority_url[89:-61]
    if "%" in search_term: # If there was a word search, I only search for the first word
        search_term = search_term.split("%")[0] (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_artist_record:[53:59]
==bpf_be_fastapi.parse_gnd_old:[745:752]
        if pe.name_variant:
            name_variant_preview = ", also called: "
            for variant in pe.name_variant:
                name_variant_preview = name_variant_preview + variant + "; "
            name_variant_preview = name_variant_preview[:-2]

 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[211:219]
==bpf_be_fastapi.ingest_person:[352:358]
                place_id = classes.ExternalReference()
                place_id.name = "viaf"
                place_id.uri = location_viaf_url
                place_id.id = location_viaf_url[21:]
                connected_location.external_id.append(place_id)
 (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.parse_istc:[447:455]
==bpf_be_fastapi.parse_istc_old:[344:352]
        if date_year != "":
        #This is not the case if there is a date such as "Between Jan. and Oct. 1488"
            string_year = date_year + " "
            start_year = int(date_year)
            end_year = int(date_year)
    elif date_prefix != "" and date_year_to == "" and date_between_year == "":
        #If there is only one date, that is not exact
#                    print("only one year, but prefixes") (duplicate-code)
test_parse_manifests.py:1:0: R0801: Similar lines in 2 files
==bpf_be_fastapi.ingest_organisation:[242:250]
==bpf_be_fastapi.ingest_place:[350:356]
                        break

# Similar features have to be added for connected organisations and places, once this is possible.

            new_connected_person = classes.Edge()
            new_connected_person.id = connected_person.id
            new_connected_person.name = connected_person.name
            new_connected_person.external_id = connected_person.external_id (duplicate-code)

------------------------------------------------------------------
Your code has been rated at 8.50/10 (previous run: 8.50/10, +0.00)

